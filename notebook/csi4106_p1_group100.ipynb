{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "1uDYBuiQ_R9K",
        "8wzYDM3a8rfR",
        "0EGBDxly9NJv",
        "NQ1sXb6f9g0o",
        "LyflcQVO9qJL",
        "lkIfBMrN9yIR",
        "gwn_Ph5E97Ek",
        "hgaSIK6H-IwI",
        "kv1xpwxy-OLR",
        "Qh-AlFVBBAFy",
        "xrSSXz9mBBaU",
        "u0euvLqX-I95",
        "vYl6InvVBGzU",
        "xbUEo6sJBJ7I",
        "OjfFffEa-TPi",
        "PHljyPtKBMcb",
        "lFfdbxBeBOwU",
        "rzRPo9x0-JIZ",
        "ngpXZ0sk_ztE",
        "g--UAsBaCxFs",
        "Pmbj_bRXCxUt",
        "ppc-z4MQ_3k2",
        "cSepwnKhC15S",
        "HLBu3hDCC2Ey",
        "dRel2XbS_3vZ",
        "Xs5jIqvZC4j_",
        "lXMxSEn3C4rE",
        "qn1qi27Q-J_h",
        "eVQlogFiAXJB",
        "R12H2xYWDJFL",
        "2UMQjM04DJLW",
        "lnoeZm0zAbc_",
        "OdxB8cUSDLqy",
        "nLRrQmZ-DLte",
        "6bRIiRCDActK",
        "V3dUu650DOE6",
        "UzUHM76JDOLx",
        "iE2e4xgb-KI0",
        "E4_7R0Og_VV7",
        "ON4Bin9TE973"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChrisHamilton91/csi4106-project1/blob/master/notebook/csi4106_p1_group100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This code block prepares a fresh VM to execute any other code block\n",
        "#### We import csv and joblib files from github, and set global variables"
      ],
      "metadata": {
        "id": "1uDYBuiQ_R9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "### DATA ###\n",
        "# class.csv - describes classes\n",
        "!wget 'https://raw.githubusercontent.com/ChrisHamilton91/csi4106-project1/master/data/class.csv'\n",
        "\n",
        "# zoo.csv - describes features\n",
        "!wget 'https://raw.githubusercontent.com/ChrisHamilton91/csi4106-project1/master/data/zoo.csv'\n",
        "\n",
        "# animals - Dataframe from zoo.csv\n",
        "!wget 'https://raw.githubusercontent.com/ChrisHamilton91/csi4106-project1/master/data/animals.joblib'\n",
        "animals = joblib.load('animals.joblib')\n",
        "\n",
        "# features - Dataframe from zoo.csv with animal_name and class_type stripped\n",
        "!wget 'https://raw.githubusercontent.com/ChrisHamilton91/csi4106-project1/master/data/features.joblib'\n",
        "features = joblib.load('features.joblib')\n",
        "\n",
        "# labels - class_type labels for features\n",
        "!wget 'https://raw.githubusercontent.com/ChrisHamilton91/csi4106-project1/master/data/labels.joblib'\n",
        "labels = joblib.load('labels.joblib')\n",
        "\n",
        "# class_dict - Dictionary of { class_number: class_name }\n",
        "!wget 'https://raw.githubusercontent.com/ChrisHamilton91/csi4106-project1/master/data/class_dict.joblib'\n",
        "class_dict = joblib.load('class_dict.joblib')\n",
        "\n",
        "# split_data - Data split into k folds\n",
        "!wget 'https://raw.githubusercontent.com/ChrisHamilton91/csi4106-project1/master/data/split_data.joblib'\n",
        "split_data = joblib.load('split_data.joblib')\n",
        "\n",
        "### MODEL RESULTS ###\n",
        "# Naive Bayes I\n",
        "## Models\n",
        "!wget 'https://raw.githubusercontent.com/ChrisHamilton91/csi4106-project1/master/model_results/nb1_models.joblib'\n",
        "nb1_models = joblib.load('nb1_models.joblib')\n",
        "## Predictions\n",
        "!wget 'https://raw.githubusercontent.com/ChrisHamilton91/csi4106-project1/master/model_results/nb1_preds.joblib'\n",
        "nb1_preds = joblib.load('nb1_preds.joblib')\n",
        "\n",
        "# Naive Bayes II\n",
        "## Models\n",
        "!wget 'https://raw.githubusercontent.com/ChrisHamilton91/csi4106-project1/master/model_results/nb2_models.joblib'\n",
        "nb2_models = joblib.load('nb2_models.joblib')\n",
        "## Predictions\n",
        "!wget 'https://raw.githubusercontent.com/ChrisHamilton91/csi4106-project1/master/model_results/nb2_preds.joblib'\n",
        "nb2_preds = joblib.load('nb2_preds.joblib')\n",
        "\n",
        "# Naive Bayes III\n",
        "## Models\n",
        "!wget 'https://raw.githubusercontent.com/ChrisHamilton91/csi4106-project1/master/model_results/nb3_models.joblib'\n",
        "nb3_models = joblib.load('nb3_models.joblib')\n",
        "## Predictions\n",
        "!wget 'https://raw.githubusercontent.com/ChrisHamilton91/csi4106-project1/master/model_results/nb3_preds.joblib'\n",
        "nb3_preds = joblib.load('nb3_preds.joblib')\n",
        "\n",
        "# MLP I\n",
        "## Models\n",
        "!wget 'https://raw.githubusercontent.com/ChrisHamilton91/csi4106-project1/master/model_results/mlp1_models.joblib'\n",
        "mlp1_models = joblib.load('mlp1_models.joblib')\n",
        "## Predictions\n",
        "!wget 'https://raw.githubusercontent.com/ChrisHamilton91/csi4106-project1/master/model_results/mlp1_preds.joblib'\n",
        "mlp1_preds = joblib.load('mlp1_preds.joblib')\n",
        "\n",
        "# MLP II\n",
        "## Models\n",
        "!wget 'https://raw.githubusercontent.com/ChrisHamilton91/csi4106-project1/master/model_results/mlp2_models.joblib'\n",
        "mlp2_models = joblib.load('mlp2_models.joblib')\n",
        "## Predictions\n",
        "!wget 'https://raw.githubusercontent.com/ChrisHamilton91/csi4106-project1/master/model_results/mlp2_preds.joblib'\n",
        "mlp2_preds = joblib.load('mlp2_preds.joblib')\n",
        "\n",
        "# MLP III\n",
        "## Models\n",
        "!wget 'https://raw.githubusercontent.com/ChrisHamilton91/csi4106-project1/master/model_results/mlp3_models.joblib'\n",
        "mlp3_models = joblib.load('mlp3_models.joblib')\n",
        "## Predictions\n",
        "!wget 'https://raw.githubusercontent.com/ChrisHamilton91/csi4106-project1/master/model_results/mlp3_preds.joblib'\n",
        "mlp3_preds = joblib.load('mlp3_preds.joblib')"
      ],
      "metadata": {
        "id": "KWztV75Q-5iU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CSI 4106 Project 1 \n",
        "# Group 100"
      ],
      "metadata": {
        "id": "8wzYDM3a8rfR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Understand the classification task"
      ],
      "metadata": {
        "id": "0EGBDxly9NJv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. Is it a binary/multi-class classification dataset?"
      ],
      "metadata": {
        "id": "auDKUNOcBrt6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. What is the goal? Is this for a particular classification study?"
      ],
      "metadata": {
        "id": "yi52qgJiWTA2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Analyze the dataset"
      ],
      "metadata": {
        "id": "NQ1sXb6f9g0o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. Characterize the dataset in terms of number of training examples, number of features, missing data etc."
      ],
      "metadata": {
        "id": "PAk9fV-WBxiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Brainstorm about attributes"
      ],
      "metadata": {
        "id": "LyflcQVO9qJL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a.Think about the features that could be used for this task. "
      ],
      "metadata": {
        "id": "WvoodNtLBx6F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Encode the features"
      ],
      "metadata": {
        "id": "lkIfBMrN9yIR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The features are encoded as discrete values in the file 'zoo.csv'. We just need to strip the 'animal_name' and 'class_type' columns.\n",
        "\n",
        "We encode the 'class_type' column as the feature labels.\n",
        "\n",
        "We will also extract the names of classes from 'class.csv', and map them to their associated number.\n",
        "\n",
        "We save the objects to a joblib file and transfer them to github for persistence. You can see them being imported at the top of the notebook."
      ],
      "metadata": {
        "id": "n2AZxvtTByqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "animals = pd.read_csv('zoo.csv')\n",
        "joblib.dump(animals, 'animals.joblib')\n",
        "\n",
        "features = animals.iloc[:,1:-1] # trim animal name and class_type\n",
        "joblib.dump(features, 'features.joblib')\n",
        "\n",
        "labels = animals.iloc[:,-1] # just class_type\n",
        "joblib.dump(labels, 'labels.joblib')\n",
        "\n",
        "classes = pd.read_csv('class.csv')\n",
        "class_dict = {}\n",
        "for _, row in classes.iterrows():\n",
        "   class_dict[row.Class_Number] = row.Class_Type\n",
        "joblib.dump(class_dict, 'class_dict.joblib')\n",
        "\n",
        "print('***************ANIMALS***************')\n",
        "print()\n",
        "print(animals)\n",
        "print()\n",
        "print('***************FEATURES***************')\n",
        "print()\n",
        "print(features)\n",
        "print()\n",
        "print('***************LABELS***************')\n",
        "print()\n",
        "print(labels)\n",
        "print()\n",
        "print('***************CLASS_DICT***************')\n",
        "print()\n",
        "print(class_dict)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lt4-mnf9-Q6",
        "outputId": "a454fa17-c142-40e0-ea60-7b496bb62501"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***************ANIMALS***************\n",
            "\n",
            "    animal_name  hair  feathers  eggs  milk  airborne  aquatic  predator  \\\n",
            "0      aardvark     1         0     0     1         0        0         1   \n",
            "1      antelope     1         0     0     1         0        0         0   \n",
            "2          bass     0         0     1     0         0        1         1   \n",
            "3          bear     1         0     0     1         0        0         1   \n",
            "4          boar     1         0     0     1         0        0         1   \n",
            "..          ...   ...       ...   ...   ...       ...      ...       ...   \n",
            "96      wallaby     1         0     0     1         0        0         0   \n",
            "97         wasp     1         0     1     0         1        0         0   \n",
            "98         wolf     1         0     0     1         0        0         1   \n",
            "99         worm     0         0     1     0         0        0         0   \n",
            "100        wren     0         1     1     0         1        0         0   \n",
            "\n",
            "     toothed  backbone  breathes  venomous  fins  legs  tail  domestic  \\\n",
            "0          1         1         1         0     0     4     0         0   \n",
            "1          1         1         1         0     0     4     1         0   \n",
            "2          1         1         0         0     1     0     1         0   \n",
            "3          1         1         1         0     0     4     0         0   \n",
            "4          1         1         1         0     0     4     1         0   \n",
            "..       ...       ...       ...       ...   ...   ...   ...       ...   \n",
            "96         1         1         1         0     0     2     1         0   \n",
            "97         0         0         1         1     0     6     0         0   \n",
            "98         1         1         1         0     0     4     1         0   \n",
            "99         0         0         1         0     0     0     0         0   \n",
            "100        0         1         1         0     0     2     1         0   \n",
            "\n",
            "     catsize  class_type  \n",
            "0          1           1  \n",
            "1          1           1  \n",
            "2          0           4  \n",
            "3          1           1  \n",
            "4          1           1  \n",
            "..       ...         ...  \n",
            "96         1           1  \n",
            "97         0           6  \n",
            "98         1           1  \n",
            "99         0           7  \n",
            "100        0           2  \n",
            "\n",
            "[101 rows x 18 columns]\n",
            "\n",
            "***************FEATURES***************\n",
            "\n",
            "     hair  feathers  eggs  milk  airborne  aquatic  predator  toothed  \\\n",
            "0       1         0     0     1         0        0         1        1   \n",
            "1       1         0     0     1         0        0         0        1   \n",
            "2       0         0     1     0         0        1         1        1   \n",
            "3       1         0     0     1         0        0         1        1   \n",
            "4       1         0     0     1         0        0         1        1   \n",
            "..    ...       ...   ...   ...       ...      ...       ...      ...   \n",
            "96      1         0     0     1         0        0         0        1   \n",
            "97      1         0     1     0         1        0         0        0   \n",
            "98      1         0     0     1         0        0         1        1   \n",
            "99      0         0     1     0         0        0         0        0   \n",
            "100     0         1     1     0         1        0         0        0   \n",
            "\n",
            "     backbone  breathes  venomous  fins  legs  tail  domestic  catsize  \n",
            "0           1         1         0     0     4     0         0        1  \n",
            "1           1         1         0     0     4     1         0        1  \n",
            "2           1         0         0     1     0     1         0        0  \n",
            "3           1         1         0     0     4     0         0        1  \n",
            "4           1         1         0     0     4     1         0        1  \n",
            "..        ...       ...       ...   ...   ...   ...       ...      ...  \n",
            "96          1         1         0     0     2     1         0        1  \n",
            "97          0         1         1     0     6     0         0        0  \n",
            "98          1         1         0     0     4     1         0        1  \n",
            "99          0         1         0     0     0     0         0        0  \n",
            "100         1         1         0     0     2     1         0        0  \n",
            "\n",
            "[101 rows x 16 columns]\n",
            "\n",
            "***************LABELS***************\n",
            "\n",
            "0      1\n",
            "1      1\n",
            "2      4\n",
            "3      1\n",
            "4      1\n",
            "      ..\n",
            "96     1\n",
            "97     6\n",
            "98     1\n",
            "99     7\n",
            "100    2\n",
            "Name: class_type, Length: 101, dtype: int64\n",
            "\n",
            "***************CLASS_DICT***************\n",
            "\n",
            "{1: 'Mammal', 2: 'Bird', 3: 'Reptile', 4: 'Fish', 5: 'Amphibian', 6: 'Bug', 7: 'Invertebrate'}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Prepare data using cross-validation"
      ],
      "metadata": {
        "id": "gwn_Ph5E97Ek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use 4-fold cross-validation."
      ],
      "metadata": {
        "id": "VADLEWSJB3Wa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(4)\n",
        "data_indices = kf.split(features, labels)\n",
        "\n",
        "split_data = []\n",
        "for train_indices, test_indices in data_indices:\n",
        "  split_data.append({\n",
        "      'train_data': features.iloc[train_indices], \n",
        "      'train_labels': labels.iloc[train_indices],\n",
        "      'test_data': features.iloc[test_indices],\n",
        "      'test_labels': labels.iloc[test_indices]})\n",
        "\n",
        "i = 0\n",
        "for d in split_data:\n",
        "  print(f'***Train Data {i}***')\n",
        "  print(d['train_data'])\n",
        "  print(f'***Train Labels {i}***')\n",
        "  print(d['train_labels'])\n",
        "  print(f'***Test Data {i}***')\n",
        "  print(d['test_data'])\n",
        "  print(f'***Test Labels {i}***')\n",
        "  print(d['test_labels'])\n",
        "  i += 1\n",
        "\n",
        "joblib.dump(split_data, 'split_data.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQU1XEbpJti4",
        "outputId": "f3d18b35-c898-4619-8483-0661ca7840b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***Train Data 0***\n",
            "     hair  feathers  eggs  milk  airborne  aquatic  predator  toothed  \\\n",
            "26      0         0     1     0         0        1         1        1   \n",
            "27      1         0     0     1         1        0         0        1   \n",
            "28      1         0     0     1         0        0         0        1   \n",
            "29      1         0     0     1         0        0         1        1   \n",
            "30      0         0     1     0         1        0         0        0   \n",
            "..    ...       ...   ...   ...       ...      ...       ...      ...   \n",
            "96      1         0     0     1         0        0         0        1   \n",
            "97      1         0     1     0         1        0         0        0   \n",
            "98      1         0     0     1         0        0         1        1   \n",
            "99      0         0     1     0         0        0         0        0   \n",
            "100     0         1     1     0         1        0         0        0   \n",
            "\n",
            "     backbone  breathes  venomous  fins  legs  tail  domestic  catsize  \n",
            "26          1         1         1     0     4     0         0        0  \n",
            "27          1         1         0     0     2     1         0        0  \n",
            "28          1         1         0     0     4     1         0        1  \n",
            "29          1         1         0     0     2     0         1        1  \n",
            "30          0         1         0     0     6     0         0        0  \n",
            "..        ...       ...       ...   ...   ...   ...       ...      ...  \n",
            "96          1         1         0     0     2     1         0        1  \n",
            "97          0         1         1     0     6     0         0        0  \n",
            "98          1         1         0     0     4     1         0        1  \n",
            "99          0         1         0     0     0     0         0        0  \n",
            "100         1         1         0     0     2     1         0        0  \n",
            "\n",
            "[75 rows x 16 columns]\n",
            "***Train Labels 0***\n",
            "26     5\n",
            "27     1\n",
            "28     1\n",
            "29     1\n",
            "30     6\n",
            "      ..\n",
            "96     1\n",
            "97     6\n",
            "98     1\n",
            "99     7\n",
            "100    2\n",
            "Name: class_type, Length: 75, dtype: int64\n",
            "***Test Data 0***\n",
            "    hair  feathers  eggs  milk  airborne  aquatic  predator  toothed  \\\n",
            "0      1         0     0     1         0        0         1        1   \n",
            "1      1         0     0     1         0        0         0        1   \n",
            "2      0         0     1     0         0        1         1        1   \n",
            "3      1         0     0     1         0        0         1        1   \n",
            "4      1         0     0     1         0        0         1        1   \n",
            "5      1         0     0     1         0        0         0        1   \n",
            "6      1         0     0     1         0        0         0        1   \n",
            "7      0         0     1     0         0        1         0        1   \n",
            "8      0         0     1     0         0        1         1        1   \n",
            "9      1         0     0     1         0        0         0        1   \n",
            "10     1         0     0     1         0        0         1        1   \n",
            "11     0         1     1     0         1        0         0        0   \n",
            "12     0         0     1     0         0        1         1        1   \n",
            "13     0         0     1     0         0        0         1        0   \n",
            "14     0         0     1     0         0        1         1        0   \n",
            "15     0         0     1     0         0        1         1        0   \n",
            "16     0         1     1     0         1        0         1        0   \n",
            "17     1         0     0     1         0        0         0        1   \n",
            "18     0         0     1     0         0        1         1        1   \n",
            "19     0         0     0     1         0        1         1        1   \n",
            "20     0         1     1     0         1        0         0        0   \n",
            "21     0         1     1     0         1        1         0        0   \n",
            "22     1         0     0     1         0        0         0        1   \n",
            "23     0         1     1     0         1        0         0        0   \n",
            "24     0         0     1     0         0        0         0        0   \n",
            "25     0         0     1     0         0        1         1        1   \n",
            "\n",
            "    backbone  breathes  venomous  fins  legs  tail  domestic  catsize  \n",
            "0          1         1         0     0     4     0         0        1  \n",
            "1          1         1         0     0     4     1         0        1  \n",
            "2          1         0         0     1     0     1         0        0  \n",
            "3          1         1         0     0     4     0         0        1  \n",
            "4          1         1         0     0     4     1         0        1  \n",
            "5          1         1         0     0     4     1         0        1  \n",
            "6          1         1         0     0     4     1         1        1  \n",
            "7          1         0         0     1     0     1         1        0  \n",
            "8          1         0         0     1     0     1         0        0  \n",
            "9          1         1         0     0     4     0         1        0  \n",
            "10         1         1         0     0     4     1         0        1  \n",
            "11         1         1         0     0     2     1         1        0  \n",
            "12         1         0         0     1     0     1         0        0  \n",
            "13         0         0         0     0     0     0         0        0  \n",
            "14         0         0         0     0     4     0         0        0  \n",
            "15         0         0         0     0     6     0         0        0  \n",
            "16         1         1         0     0     2     1         0        0  \n",
            "17         1         1         0     0     4     1         0        1  \n",
            "18         1         0         0     1     0     1         0        1  \n",
            "19         1         1         0     1     0     1         0        1  \n",
            "20         1         1         0     0     2     1         1        0  \n",
            "21         1         1         0     0     2     1         0        0  \n",
            "22         1         1         0     0     4     1         0        1  \n",
            "23         1         1         0     0     2     1         0        1  \n",
            "24         0         1         0     0     6     0         0        0  \n",
            "25         1         1         0     0     4     0         0        0  \n",
            "***Test Labels 0***\n",
            "0     1\n",
            "1     1\n",
            "2     4\n",
            "3     1\n",
            "4     1\n",
            "5     1\n",
            "6     1\n",
            "7     4\n",
            "8     4\n",
            "9     1\n",
            "10    1\n",
            "11    2\n",
            "12    4\n",
            "13    7\n",
            "14    7\n",
            "15    7\n",
            "16    2\n",
            "17    1\n",
            "18    4\n",
            "19    1\n",
            "20    2\n",
            "21    2\n",
            "22    1\n",
            "23    2\n",
            "24    6\n",
            "25    5\n",
            "Name: class_type, dtype: int64\n",
            "***Train Data 1***\n",
            "     hair  feathers  eggs  milk  airborne  aquatic  predator  toothed  \\\n",
            "0       1         0     0     1         0        0         1        1   \n",
            "1       1         0     0     1         0        0         0        1   \n",
            "2       0         0     1     0         0        1         1        1   \n",
            "3       1         0     0     1         0        0         1        1   \n",
            "4       1         0     0     1         0        0         1        1   \n",
            "..    ...       ...   ...   ...       ...      ...       ...      ...   \n",
            "96      1         0     0     1         0        0         0        1   \n",
            "97      1         0     1     0         1        0         0        0   \n",
            "98      1         0     0     1         0        0         1        1   \n",
            "99      0         0     1     0         0        0         0        0   \n",
            "100     0         1     1     0         1        0         0        0   \n",
            "\n",
            "     backbone  breathes  venomous  fins  legs  tail  domestic  catsize  \n",
            "0           1         1         0     0     4     0         0        1  \n",
            "1           1         1         0     0     4     1         0        1  \n",
            "2           1         0         0     1     0     1         0        0  \n",
            "3           1         1         0     0     4     0         0        1  \n",
            "4           1         1         0     0     4     1         0        1  \n",
            "..        ...       ...       ...   ...   ...   ...       ...      ...  \n",
            "96          1         1         0     0     2     1         0        1  \n",
            "97          0         1         1     0     6     0         0        0  \n",
            "98          1         1         0     0     4     1         0        1  \n",
            "99          0         1         0     0     0     0         0        0  \n",
            "100         1         1         0     0     2     1         0        0  \n",
            "\n",
            "[76 rows x 16 columns]\n",
            "***Train Labels 1***\n",
            "0      1\n",
            "1      1\n",
            "2      4\n",
            "3      1\n",
            "4      1\n",
            "      ..\n",
            "96     1\n",
            "97     6\n",
            "98     1\n",
            "99     7\n",
            "100    2\n",
            "Name: class_type, Length: 76, dtype: int64\n",
            "***Test Data 1***\n",
            "    hair  feathers  eggs  milk  airborne  aquatic  predator  toothed  \\\n",
            "26     0         0     1     0         0        1         1        1   \n",
            "27     1         0     0     1         1        0         0        1   \n",
            "28     1         0     0     1         0        0         0        1   \n",
            "29     1         0     0     1         0        0         1        1   \n",
            "30     0         0     1     0         1        0         0        0   \n",
            "31     1         0     0     1         0        0         0        1   \n",
            "32     1         0     0     1         0        0         0        1   \n",
            "33     0         1     1     0         1        1         1        0   \n",
            "34     0         0     1     0         0        1         0        1   \n",
            "35     1         0     0     1         0        0         0        1   \n",
            "36     1         0     0     1         0        0         0        1   \n",
            "37     0         1     1     0         1        0         1        0   \n",
            "38     0         0     1     0         0        1         1        1   \n",
            "39     1         0     1     0         1        0         0        0   \n",
            "40     1         0     1     0         1        0         0        0   \n",
            "41     0         1     1     0         0        0         1        0   \n",
            "42     0         0     1     0         1        0         1        0   \n",
            "43     0         1     1     0         1        0         0        0   \n",
            "44     1         0     0     1         0        0         1        1   \n",
            "45     1         0     0     1         0        0         1        1   \n",
            "46     0         0     1     0         0        1         1        0   \n",
            "47     1         0     0     1         0        0         1        1   \n",
            "48     1         0     0     1         0        1         1        1   \n",
            "49     1         0     0     1         0        0         1        1   \n",
            "50     1         0     0     1         0        0         1        1   \n",
            "\n",
            "    backbone  breathes  venomous  fins  legs  tail  domestic  catsize  \n",
            "26         1         1         1     0     4     0         0        0  \n",
            "27         1         1         0     0     2     1         0        0  \n",
            "28         1         1         0     0     4     1         0        1  \n",
            "29         1         1         0     0     2     0         1        1  \n",
            "30         0         1         0     0     6     0         0        0  \n",
            "31         1         1         0     0     4     1         1        1  \n",
            "32         1         1         0     0     2     0         0        1  \n",
            "33         1         1         0     0     2     1         0        0  \n",
            "34         1         0         0     1     0     1         0        0  \n",
            "35         1         1         0     0     4     1         1        0  \n",
            "36         1         1         0     0     4     1         0        0  \n",
            "37         1         1         0     0     2     1         0        0  \n",
            "38         1         0         0     1     0     1         0        0  \n",
            "39         0         1         1     0     6     0         1        0  \n",
            "40         0         1         0     0     6     0         0        0  \n",
            "41         1         1         0     0     2     1         0        0  \n",
            "42         0         1         0     0     6     0         0        0  \n",
            "43         1         1         0     0     2     1         0        0  \n",
            "44         1         1         0     0     4     1         0        1  \n",
            "45         1         1         0     0     4     1         0        1  \n",
            "46         0         0         0     0     6     0         0        0  \n",
            "47         1         1         0     0     4     1         0        1  \n",
            "48         1         1         0     0     4     1         0        1  \n",
            "49         1         1         0     0     4     1         0        0  \n",
            "50         1         1         0     0     4     1         0        1  \n",
            "***Test Labels 1***\n",
            "26    5\n",
            "27    1\n",
            "28    1\n",
            "29    1\n",
            "30    6\n",
            "31    1\n",
            "32    1\n",
            "33    2\n",
            "34    4\n",
            "35    1\n",
            "36    1\n",
            "37    2\n",
            "38    4\n",
            "39    6\n",
            "40    6\n",
            "41    2\n",
            "42    6\n",
            "43    2\n",
            "44    1\n",
            "45    1\n",
            "46    7\n",
            "47    1\n",
            "48    1\n",
            "49    1\n",
            "50    1\n",
            "Name: class_type, dtype: int64\n",
            "***Train Data 2***\n",
            "     hair  feathers  eggs  milk  airborne  aquatic  predator  toothed  \\\n",
            "0       1         0     0     1         0        0         1        1   \n",
            "1       1         0     0     1         0        0         0        1   \n",
            "2       0         0     1     0         0        1         1        1   \n",
            "3       1         0     0     1         0        0         1        1   \n",
            "4       1         0     0     1         0        0         1        1   \n",
            "..    ...       ...   ...   ...       ...      ...       ...      ...   \n",
            "96      1         0     0     1         0        0         0        1   \n",
            "97      1         0     1     0         1        0         0        0   \n",
            "98      1         0     0     1         0        0         1        1   \n",
            "99      0         0     1     0         0        0         0        0   \n",
            "100     0         1     1     0         1        0         0        0   \n",
            "\n",
            "     backbone  breathes  venomous  fins  legs  tail  domestic  catsize  \n",
            "0           1         1         0     0     4     0         0        1  \n",
            "1           1         1         0     0     4     1         0        1  \n",
            "2           1         0         0     1     0     1         0        0  \n",
            "3           1         1         0     0     4     0         0        1  \n",
            "4           1         1         0     0     4     1         0        1  \n",
            "..        ...       ...       ...   ...   ...   ...       ...      ...  \n",
            "96          1         1         0     0     2     1         0        1  \n",
            "97          0         1         1     0     6     0         0        0  \n",
            "98          1         1         0     0     4     1         0        1  \n",
            "99          0         1         0     0     0     0         0        0  \n",
            "100         1         1         0     0     2     1         0        0  \n",
            "\n",
            "[76 rows x 16 columns]\n",
            "***Train Labels 2***\n",
            "0      1\n",
            "1      1\n",
            "2      4\n",
            "3      1\n",
            "4      1\n",
            "      ..\n",
            "96     1\n",
            "97     6\n",
            "98     1\n",
            "99     7\n",
            "100    2\n",
            "Name: class_type, Length: 76, dtype: int64\n",
            "***Test Data 2***\n",
            "    hair  feathers  eggs  milk  airborne  aquatic  predator  toothed  \\\n",
            "51     1         0     1     0         1        0         0        0   \n",
            "52     0         0     1     0         0        1         1        1   \n",
            "53     0         0     1     0         0        1         1        0   \n",
            "54     1         0     0     1         0        0         1        1   \n",
            "55     1         0     0     1         0        0         0        1   \n",
            "56     0         1     1     0         0        0         0        0   \n",
            "57     0         1     1     0         1        0         0        0   \n",
            "58     0         1     1     0         0        1         1        0   \n",
            "59     0         1     1     0         1        0         0        0   \n",
            "60     0         0     1     0         0        1         1        1   \n",
            "61     0         0     1     0         0        1         1        1   \n",
            "62     0         0     1     0         0        0         1        1   \n",
            "63     1         0     1     1         0        1         1        0   \n",
            "64     1         0     0     1         0        0         1        1   \n",
            "65     1         0     0     1         0        0         0        1   \n",
            "66     0         0     0     1         0        1         1        1   \n",
            "67     1         0     0     1         0        0         1        1   \n",
            "68     1         0     0     1         0        0         1        1   \n",
            "69     1         0     0     1         0        0         1        1   \n",
            "70     1         0     0     1         0        0         0        1   \n",
            "71     0         1     1     0         0        0         1        0   \n",
            "72     0         0     0     0         0        0         1        0   \n",
            "73     0         0     1     0         0        1         0        1   \n",
            "74     1         0     0     1         0        1         1        1   \n",
            "75     1         0     0     1         0        1         1        1   \n",
            "\n",
            "    backbone  breathes  venomous  fins  legs  tail  domestic  catsize  \n",
            "51         0         1         0     0     6     0         0        0  \n",
            "52         1         1         0     0     4     1         0        0  \n",
            "53         0         0         0     0     8     0         0        1  \n",
            "54         1         1         0     0     4     1         0        0  \n",
            "55         1         1         0     0     4     1         0        1  \n",
            "56         1         1         0     0     2     1         0        1  \n",
            "57         1         1         0     0     2     1         1        0  \n",
            "58         1         1         0     0     2     1         0        1  \n",
            "59         1         1         0     0     2     1         0        0  \n",
            "60         1         0         0     1     0     1         0        1  \n",
            "61         1         0         0     1     0     1         0        0  \n",
            "62         1         1         1     0     0     1         0        0  \n",
            "63         1         1         0     0     4     1         0        1  \n",
            "64         1         1         0     0     4     1         0        1  \n",
            "65         1         1         0     0     4     1         1        1  \n",
            "66         1         1         0     1     0     1         0        1  \n",
            "67         1         1         0     0     4     1         0        1  \n",
            "68         1         1         0     0     4     1         1        1  \n",
            "69         1         1         0     0     4     1         0        1  \n",
            "70         1         1         0     0     4     1         1        1  \n",
            "71         1         1         0     0     2     1         0        1  \n",
            "72         0         1         1     0     8     1         0        0  \n",
            "73         1         0         0     1     0     1         0        0  \n",
            "74         1         1         0     1     0     0         0        1  \n",
            "75         1         1         0     1     2     1         0        1  \n",
            "***Test Labels 2***\n",
            "51    6\n",
            "52    5\n",
            "53    7\n",
            "54    1\n",
            "55    1\n",
            "56    2\n",
            "57    2\n",
            "58    2\n",
            "59    2\n",
            "60    4\n",
            "61    4\n",
            "62    3\n",
            "63    1\n",
            "64    1\n",
            "65    1\n",
            "66    1\n",
            "67    1\n",
            "68    1\n",
            "69    1\n",
            "70    1\n",
            "71    2\n",
            "72    7\n",
            "73    4\n",
            "74    1\n",
            "75    1\n",
            "Name: class_type, dtype: int64\n",
            "***Train Data 3***\n",
            "    hair  feathers  eggs  milk  airborne  aquatic  predator  toothed  \\\n",
            "0      1         0     0     1         0        0         1        1   \n",
            "1      1         0     0     1         0        0         0        1   \n",
            "2      0         0     1     0         0        1         1        1   \n",
            "3      1         0     0     1         0        0         1        1   \n",
            "4      1         0     0     1         0        0         1        1   \n",
            "..   ...       ...   ...   ...       ...      ...       ...      ...   \n",
            "71     0         1     1     0         0        0         1        0   \n",
            "72     0         0     0     0         0        0         1        0   \n",
            "73     0         0     1     0         0        1         0        1   \n",
            "74     1         0     0     1         0        1         1        1   \n",
            "75     1         0     0     1         0        1         1        1   \n",
            "\n",
            "    backbone  breathes  venomous  fins  legs  tail  domestic  catsize  \n",
            "0          1         1         0     0     4     0         0        1  \n",
            "1          1         1         0     0     4     1         0        1  \n",
            "2          1         0         0     1     0     1         0        0  \n",
            "3          1         1         0     0     4     0         0        1  \n",
            "4          1         1         0     0     4     1         0        1  \n",
            "..       ...       ...       ...   ...   ...   ...       ...      ...  \n",
            "71         1         1         0     0     2     1         0        1  \n",
            "72         0         1         1     0     8     1         0        0  \n",
            "73         1         0         0     1     0     1         0        0  \n",
            "74         1         1         0     1     0     0         0        1  \n",
            "75         1         1         0     1     2     1         0        1  \n",
            "\n",
            "[76 rows x 16 columns]\n",
            "***Train Labels 3***\n",
            "0     1\n",
            "1     1\n",
            "2     4\n",
            "3     1\n",
            "4     1\n",
            "     ..\n",
            "71    2\n",
            "72    7\n",
            "73    4\n",
            "74    1\n",
            "75    1\n",
            "Name: class_type, Length: 76, dtype: int64\n",
            "***Test Data 3***\n",
            "     hair  feathers  eggs  milk  airborne  aquatic  predator  toothed  \\\n",
            "76      0         0     0     0         0        1         1        1   \n",
            "77      0         0     1     0         0        1         1        0   \n",
            "78      0         1     1     0         1        1         1        0   \n",
            "79      0         1     1     0         1        1         1        0   \n",
            "80      0         0     1     0         0        0         1        1   \n",
            "81      0         0     1     0         0        0         0        0   \n",
            "82      0         0     1     0         0        1         0        1   \n",
            "83      0         1     1     0         1        0         0        0   \n",
            "84      1         0     0     1         0        0         0        1   \n",
            "85      0         0     1     0         0        1         1        0   \n",
            "86      0         0     1     0         0        1         1        1   \n",
            "87      0         1     1     0         1        1         0        0   \n",
            "88      0         0     1     0         0        0         0        0   \n",
            "89      0         0     1     0         0        1         0        1   \n",
            "90      0         0     1     0         0        0         0        0   \n",
            "91      0         0     1     0         0        0         1        1   \n",
            "92      0         0     1     0         0        1         1        1   \n",
            "93      1         0     0     1         1        0         0        1   \n",
            "94      1         0     0     1         0        0         0        1   \n",
            "95      0         1     1     0         1        0         1        0   \n",
            "96      1         0     0     1         0        0         0        1   \n",
            "97      1         0     1     0         1        0         0        0   \n",
            "98      1         0     0     1         0        0         1        1   \n",
            "99      0         0     1     0         0        0         0        0   \n",
            "100     0         1     1     0         1        0         0        0   \n",
            "\n",
            "     backbone  breathes  venomous  fins  legs  tail  domestic  catsize  \n",
            "76          1         0         1     0     0     1         0        0  \n",
            "77          0         0         1     0     0     0         0        0  \n",
            "78          1         1         0     0     2     1         0        0  \n",
            "79          1         1         0     0     2     1         0        0  \n",
            "80          1         1         0     0     0     1         0        0  \n",
            "81          0         1         0     0     0     0         0        0  \n",
            "82          1         0         0     1     0     1         0        0  \n",
            "83          1         1         0     0     2     1         0        0  \n",
            "84          1         1         0     0     2     1         0        0  \n",
            "85          0         0         0     0     5     0         0        0  \n",
            "86          1         0         1     1     0     1         0        1  \n",
            "87          1         1         0     0     2     1         0        1  \n",
            "88          0         1         0     0     6     0         0        0  \n",
            "89          1         1         0     0     4     0         0        0  \n",
            "90          1         1         0     0     4     1         0        1  \n",
            "91          1         1         0     0     4     1         0        0  \n",
            "92          1         0         0     1     0     1         0        1  \n",
            "93          1         1         0     0     2     1         0        0  \n",
            "94          1         1         0     0     4     1         0        0  \n",
            "95          1         1         0     0     2     1         0        1  \n",
            "96          1         1         0     0     2     1         0        1  \n",
            "97          0         1         1     0     6     0         0        0  \n",
            "98          1         1         0     0     4     1         0        1  \n",
            "99          0         1         0     0     0     0         0        0  \n",
            "100         1         1         0     0     2     1         0        0  \n",
            "***Test Labels 3***\n",
            "76     3\n",
            "77     7\n",
            "78     2\n",
            "79     2\n",
            "80     3\n",
            "81     7\n",
            "82     4\n",
            "83     2\n",
            "84     1\n",
            "85     7\n",
            "86     4\n",
            "87     2\n",
            "88     6\n",
            "89     5\n",
            "90     3\n",
            "91     3\n",
            "92     4\n",
            "93     1\n",
            "94     1\n",
            "95     2\n",
            "96     1\n",
            "97     6\n",
            "98     1\n",
            "99     7\n",
            "100    2\n",
            "Name: class_type, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['split_data.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Train 3 models"
      ],
      "metadata": {
        "id": "hgaSIK6H-IwI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Bayes I"
      ],
      "metadata": {
        "id": "kv1xpwxy-OLR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bernoulli Naive Bayes with default parameters\n",
        "\n",
        "`alpha`: 1.0\n",
        "\n",
        "`fit_prior`: true"
      ],
      "metadata": {
        "id": "hOEqTL45k6N5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "nb1_models = []\n",
        "for d in split_data:\n",
        "  bnb = BernoulliNB()\n",
        "  nb1_models.append(bnb.fit(d['train_data'], d['train_labels']))\n",
        "\n",
        "joblib.dump(nb1_models, 'nb1_models.joblib')\n",
        "\n",
        "print(nb1_models)"
      ],
      "metadata": {
        "id": "5imEJaB9-xU2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d8f69f4-ec88-45fc-e0cb-e094bb839270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BernoulliNB(), BernoulliNB(), BernoulliNB(), BernoulliNB()]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Bayes II"
      ],
      "metadata": {
        "id": "Qh-AlFVBBAFy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bernoulli Naive Bayes where alpha (smoothing parameter) is 100:\n",
        "\n",
        "`alpha`: 100.0\n",
        "\n",
        "`fit_prior`: true"
      ],
      "metadata": {
        "id": "evUJsKmnly4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "nb2_models = []\n",
        "for d in split_data:\n",
        "  bnb = BernoulliNB(alpha=100)\n",
        "  nb2_models.append(bnb.fit(d['train_data'], d['train_labels']))\n",
        "\n",
        "joblib.dump(nb2_models, 'nb2_models.joblib')\n",
        "\n",
        "print(nb2_models)"
      ],
      "metadata": {
        "id": "ZfRX2_zxBBaU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "246c7e2d-d186-4bbb-fa0b-578bb300167f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BernoulliNB(alpha=100), BernoulliNB(alpha=100), BernoulliNB(alpha=100), BernoulliNB(alpha=100)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Bayes III"
      ],
      "metadata": {
        "id": "xrSSXz9mBBaU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bernoulli Naive Bayes where fit_prior is False, which uses a uniform prior:\n",
        "\n",
        "`alpha`: 1.0\n",
        "\n",
        "`fit_prior`: false"
      ],
      "metadata": {
        "id": "DI7fcaoWmchj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "nb3_models = []\n",
        "for d in split_data:\n",
        "  bnb = BernoulliNB(fit_prior=False)\n",
        "  nb3_models.append(bnb.fit(d['train_data'], d['train_labels']))\n",
        "\n",
        "joblib.dump(nb3_models, 'nb3_models.joblib')\n",
        "\n",
        "print(nb3_models)"
      ],
      "metadata": {
        "id": "yFAvxYP-BAFz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "971ffe58-a97a-4545-87be-d73173ff3c9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BernoulliNB(fit_prior=False), BernoulliNB(fit_prior=False), BernoulliNB(fit_prior=False), BernoulliNB(fit_prior=False)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression I"
      ],
      "metadata": {
        "id": "u0euvLqX-I95"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression with default parameters\n",
        "\n",
        "Note: `max_iter` was increased due to non-convergence\n",
        "\n",
        "`tol`: 1e-4 (tolerance for judging convergence)\n",
        "\n",
        "`max_iter`: 200\n",
        "\n",
        "`C`: 1.0 (smaller values specify stronger regularization)"
      ],
      "metadata": {
        "id": "o637WHx8G4kH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr1_models = []\n",
        "for d in split_data:\n",
        "  lr = LogisticRegression(max_iter=200)\n",
        "  lr1_models.append(lr.fit(d['train_data'], d['train_labels']))\n",
        "\n",
        "joblib.dump(lr1_models, 'lr1_models.joblib')\n",
        "\n",
        "print(lr1_models)"
      ],
      "metadata": {
        "id": "MC_s89C3-x3Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51984e95-11bb-4a69-e175-cc23be8e7804"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LogisticRegression(max_iter=200), LogisticRegression(max_iter=200), LogisticRegression(max_iter=200), LogisticRegression(max_iter=200)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression II"
      ],
      "metadata": {
        "id": "vYl6InvVBGzU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression with small tolerance and 100,000 iterations\n",
        "\n",
        "`tol`: 1e-8 (tolerance for judging convergence)\n",
        "\n",
        "`max_iter`: 100 000\n",
        "\n",
        "`C`: 1.0 (smaller values specify stronger regularization)"
      ],
      "metadata": {
        "id": "JVkThb_zIkRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr2_models = []\n",
        "for d in split_data:\n",
        "  lr = LogisticRegression(tol=1e-8, max_iter=100000)\n",
        "  lr2_models.append(lr.fit(d['train_data'], d['train_labels']))\n",
        "\n",
        "joblib.dump(lr2_models, 'lr2_models.joblib')\n",
        "\n",
        "print(lr2_models)"
      ],
      "metadata": {
        "id": "idZTAKpSBGzV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f44f68a-9fc3-4408-db9a-417a967d34bc"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LogisticRegression(max_iter=100000, tol=1e-08), LogisticRegression(max_iter=100000, tol=1e-08), LogisticRegression(max_iter=100000, tol=1e-08), LogisticRegression(max_iter=100000, tol=1e-08)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression III"
      ],
      "metadata": {
        "id": "xbUEo6sJBJ7I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression with small tolerance, 1 million iterations, and strong regularization\n",
        "\n",
        "`tol`: 1e-8 (tolerance for judging convergence)\n",
        "\n",
        "`max_iter`: 1e6\n",
        "\n",
        "`C`: 0.01 (smaller values specify stronger regularization)"
      ],
      "metadata": {
        "id": "q0WDB_CoI9kA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr3_models = []\n",
        "for d in split_data:\n",
        "  lr = LogisticRegression(tol=1e-8, max_iter=int(1e6), C=0.01)\n",
        "  lr3_models.append(lr.fit(d['train_data'], d['train_labels']))\n",
        "\n",
        "joblib.dump(lr3_models, 'lr3_models.joblib')\n",
        "\n",
        "print(lr3_models)"
      ],
      "metadata": {
        "id": "wGA-5FeTBJ7J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf3cd607-6115-4ef5-ee71-61c8f35ca093"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LogisticRegression(C=0.01, max_iter=1000000, tol=1e-08), LogisticRegression(C=0.01, max_iter=1000000, tol=1e-08), LogisticRegression(C=0.01, max_iter=1000000, tol=1e-08), LogisticRegression(C=0.01, max_iter=1000000, tol=1e-08)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-Layer Perceptron I"
      ],
      "metadata": {
        "id": "OjfFffEa-TPi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi-layer Perceptron with default parameters \n",
        "\n",
        "Note: `random_state` is provided to get reproducible results\n",
        "\n",
        "Note: `max_iter` was increased due to non-convergence\n",
        "\n",
        "`random_state`: 1\n",
        "\n",
        "`hidden_layer_sizes`: (100,) (1 hidden layer of 100 units)\n",
        "\n",
        "`max_iter`: 400\n",
        "\n",
        "`tol`: 1e-4 (tolerance to judge convergence)\n",
        "\n",
        "`n_iter_no_change`: 10 (max # of epochs to meet `tol` improvement)"
      ],
      "metadata": {
        "id": "K69Vm3Xh73sO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "mlp1_models = []\n",
        "for d in split_data:\n",
        "  mlp = MLPClassifier(random_state=1, max_iter=400);\n",
        "  mlp1_models.append(mlp.fit(d['train_data'], d['train_labels']))\n",
        "\n",
        "joblib.dump(mlp1_models, 'mlp1_models.joblib')\n",
        "\n",
        "print(mlp1_models)"
      ],
      "metadata": {
        "id": "EoJLgsin-ySv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd846f23-a7f8-48c7-a719-a2f092874915"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MLPClassifier(max_iter=400, random_state=1), MLPClassifier(max_iter=400, random_state=1), MLPClassifier(max_iter=400, random_state=1), MLPClassifier(max_iter=400, random_state=1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-Layer Perceptron II"
      ],
      "metadata": {
        "id": "PHljyPtKBMcb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi-layer Perceptron with five large hidden layers and 10000 max iterations\n",
        "\n",
        "`random_state`: 1\n",
        "\n",
        "`hidden_layer_sizes`: (100, 100, 100, 100, 100) (5 layers of size 100)\n",
        "\n",
        "`max_iter`: 10000\n",
        "\n",
        "`tol`: 1e-4 (tolerance to judge convergence)\n",
        "\n",
        "`n_iter_no_change`: 10 (max # of epochs to meet `tol` improvement)"
      ],
      "metadata": {
        "id": "hpig9YL_-XCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "mlp2_models = []\n",
        "for d in split_data:\n",
        "  mlp = MLPClassifier(\n",
        "      random_state=1, \n",
        "      hidden_layer_sizes=(100, 100, 100, 100, 100), \n",
        "      max_iter=10000)\n",
        "  mlp2_models.append(mlp.fit(d['train_data'], d['train_labels']))\n",
        "\n",
        "joblib.dump(mlp2_models, 'mlp2_models.joblib')\n",
        "\n",
        "print(mlp2_models)"
      ],
      "metadata": {
        "id": "RKT796-SBMcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d077bae-57a1-48a0-8988-7d98cc5cf8a8"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MLPClassifier(hidden_layer_sizes=(100, 100, 100, 100, 100), max_iter=10000,\n",
            "              random_state=1), MLPClassifier(hidden_layer_sizes=(100, 100, 100, 100, 100), max_iter=10000,\n",
            "              random_state=1), MLPClassifier(hidden_layer_sizes=(100, 100, 100, 100, 100), max_iter=10000,\n",
            "              random_state=1), MLPClassifier(hidden_layer_sizes=(100, 100, 100, 100, 100), max_iter=10000,\n",
            "              random_state=1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-Layer Perceptron III"
      ],
      "metadata": {
        "id": "lFfdbxBeBOwU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi-layer Perceptron with ten small layers, very small tolerance, and one million max iterations\n",
        "\n",
        "`random_state`: 1\n",
        "\n",
        "`hidden_layer_sizes`: (10, 10, 10, 10, 10, 10, 10, 10, 10, 10) (10 layers of size 10)\n",
        "\n",
        "`max_iter`: 1e6\n",
        "\n",
        "`tol`: 1e-8 (tolerance to judge convergence)\n",
        "\n",
        "`n_iter_no_change`: 1000 (max # of epochs to meet `tol` improvement)"
      ],
      "metadata": {
        "id": "j5KUEBybBWlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "mlp3_models = []\n",
        "for d in split_data:\n",
        "  mlp = MLPClassifier(\n",
        "      random_state=1, \n",
        "      hidden_layer_sizes=(10, 10, 10, 10, 10, 10, 10, 10, 10, 10), \n",
        "      max_iter=int(1e6),\n",
        "      tol=1e-8,\n",
        "      n_iter_no_change=1000)\n",
        "  mlp3_models.append(mlp.fit(d['train_data'], d['train_labels']))\n",
        "\n",
        "joblib.dump(mlp3_models, 'mlp3_models.joblib')\n",
        "\n",
        "print(mlp3_models)"
      ],
      "metadata": {
        "id": "i8ij6wEKBOwV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dcc3d33-7149-495b-b0c9-671488c4d160"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MLPClassifier(hidden_layer_sizes=(10, 10, 10, 10, 10, 10, 10, 10, 10, 10),\n",
            "              max_iter=1000000, n_iter_no_change=1000, random_state=1,\n",
            "              tol=1e-08), MLPClassifier(hidden_layer_sizes=(10, 10, 10, 10, 10, 10, 10, 10, 10, 10),\n",
            "              max_iter=1000000, n_iter_no_change=1000, random_state=1,\n",
            "              tol=1e-08), MLPClassifier(hidden_layer_sizes=(10, 10, 10, 10, 10, 10, 10, 10, 10, 10),\n",
            "              max_iter=1000000, n_iter_no_change=1000, random_state=1,\n",
            "              tol=1e-08), MLPClassifier(hidden_layer_sizes=(10, 10, 10, 10, 10, 10, 10, 10, 10, 10),\n",
            "              max_iter=1000000, n_iter_no_change=1000, random_state=1,\n",
            "              tol=1e-08)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Test models using cross validation"
      ],
      "metadata": {
        "id": "rzRPo9x0-JIZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Bayes I"
      ],
      "metadata": {
        "id": "ngpXZ0sk_ztE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb1_preds = []\n",
        "\n",
        "for i, model in enumerate(nb1_models):\n",
        "  test_data = split_data[i]['test_data']\n",
        "  test_labels = split_data[i]['test_labels']\n",
        "  preds = model.predict(test_data)\n",
        "  nb1_preds.append(preds)\n",
        "\n",
        "  print(f'***Model {i} Predictions:***')\n",
        "  for j, animal_idx in enumerate(test_data.index):\n",
        "    animal_name = animals.iloc[animal_idx,0]\n",
        "    predicted_class = preds[j]\n",
        "    actual_class = test_labels.iloc[j]\n",
        "    correct = predicted_class == actual_class\n",
        "    if (correct):\n",
        "      print(animal_name + \": \" + class_dict[predicted_class] + \" \")\n",
        "    else:\n",
        "      print(animal_name + \": \" + class_dict[predicted_class] + \"  \" + class_dict[actual_class])\n",
        "  print()\n",
        "\n",
        "joblib.dump(nb1_preds, 'nb1_preds.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hSq8vL9iZL5",
        "outputId": "265259c1-5dfe-4c4c-a01f-9a61c15bd8f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***Model 0 Predictions:***\n",
            "aardvark: Mammal \n",
            "antelope: Mammal \n",
            "bass: Fish \n",
            "bear: Mammal \n",
            "boar: Mammal \n",
            "buffalo: Mammal \n",
            "calf: Mammal \n",
            "carp: Fish \n",
            "catfish: Fish \n",
            "cavy: Mammal \n",
            "cheetah: Mammal \n",
            "chicken: Bird \n",
            "chub: Fish \n",
            "clam: Invertebrate \n",
            "crab: Invertebrate \n",
            "crayfish: Invertebrate \n",
            "crow: Bird \n",
            "deer: Mammal \n",
            "dogfish: Fish \n",
            "dolphin: Mammal \n",
            "dove: Bird \n",
            "duck: Bird \n",
            "elephant: Mammal \n",
            "flamingo: Bird \n",
            "flea: Bug \n",
            "frog: Amphibian \n",
            "\n",
            "***Model 1 Predictions:***\n",
            "frog: Amphibian \n",
            "fruitbat: Mammal \n",
            "giraffe: Mammal \n",
            "girl: Mammal \n",
            "gnat: Bug \n",
            "goat: Mammal \n",
            "gorilla: Mammal \n",
            "gull: Bird \n",
            "haddock: Fish \n",
            "hamster: Mammal \n",
            "hare: Mammal \n",
            "hawk: Bird \n",
            "herring: Fish \n",
            "honeybee: Bug \n",
            "housefly: Bug \n",
            "kiwi: Bird \n",
            "ladybird: Bug \n",
            "lark: Bird \n",
            "leopard: Mammal \n",
            "lion: Mammal \n",
            "lobster: Invertebrate \n",
            "lynx: Mammal \n",
            "mink: Mammal \n",
            "mole: Mammal \n",
            "mongoose: Mammal \n",
            "\n",
            "***Model 2 Predictions:***\n",
            "moth: Bug \n",
            "newt: Reptile  Amphibian\n",
            "octopus: Invertebrate \n",
            "opossum: Mammal \n",
            "oryx: Mammal \n",
            "ostrich: Bird \n",
            "parakeet: Bird \n",
            "penguin: Bird \n",
            "pheasant: Bird \n",
            "pike: Fish \n",
            "piranha: Fish \n",
            "pitviper: Reptile \n",
            "platypus: Mammal \n",
            "polecat: Mammal \n",
            "pony: Mammal \n",
            "porpoise: Fish  Mammal\n",
            "puma: Mammal \n",
            "pussycat: Mammal \n",
            "raccoon: Mammal \n",
            "reindeer: Mammal \n",
            "rhea: Bird \n",
            "scorpion: Reptile  Invertebrate\n",
            "seahorse: Fish \n",
            "seal: Mammal \n",
            "sealion: Mammal \n",
            "\n",
            "***Model 3 Predictions:***\n",
            "seasnake: Fish  Reptile\n",
            "seawasp: Invertebrate \n",
            "skimmer: Bird \n",
            "skua: Bird \n",
            "slowworm: Amphibian  Reptile\n",
            "slug: Bug  Invertebrate\n",
            "sole: Fish \n",
            "sparrow: Bird \n",
            "squirrel: Mammal \n",
            "starfish: Invertebrate \n",
            "stingray: Fish \n",
            "swan: Bird \n",
            "termite: Bug \n",
            "toad: Amphibian \n",
            "tortoise: Bird  Reptile\n",
            "tuatara: Amphibian  Reptile\n",
            "tuna: Fish \n",
            "vampire: Mammal \n",
            "vole: Mammal \n",
            "vulture: Bird \n",
            "wallaby: Mammal \n",
            "wasp: Bug \n",
            "wolf: Mammal \n",
            "worm: Bug  Invertebrate\n",
            "wren: Bird \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nb1_preds.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Bayes II"
      ],
      "metadata": {
        "id": "g--UAsBaCxFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb2_preds = []\n",
        "\n",
        "for i, model in enumerate(nb2_models):\n",
        "  test_data = split_data[i]['test_data']\n",
        "  test_labels = split_data[i]['test_labels']\n",
        "  preds = model.predict(test_data)\n",
        "  nb2_preds.append(preds)\n",
        "\n",
        "  print(f'***Model {i} Predictions:***')\n",
        "  for j, animal_idx in enumerate(test_data.index):\n",
        "    animal_name = animals.iloc[animal_idx,0]\n",
        "    predicted_class = preds[j]\n",
        "    actual_class = test_labels.iloc[j]\n",
        "    correct = predicted_class == actual_class\n",
        "    if (correct):\n",
        "      print(animal_name + \": \" + class_dict[predicted_class] + \" \")\n",
        "    else:\n",
        "      print(animal_name + \": \" + class_dict[predicted_class] + \"  \" + class_dict[actual_class])\n",
        "  print()\n",
        "\n",
        "joblib.dump(nb2_preds, 'nb2_preds.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UECFvXJ8paiq",
        "outputId": "50d19353-088d-4b24-bf14-cd244e4e232a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***Model 0 Predictions:***\n",
            "aardvark: Mammal \n",
            "antelope: Mammal \n",
            "bass: Mammal  Fish\n",
            "bear: Mammal \n",
            "boar: Mammal \n",
            "buffalo: Mammal \n",
            "calf: Mammal \n",
            "carp: Mammal  Fish\n",
            "catfish: Mammal  Fish\n",
            "cavy: Mammal \n",
            "cheetah: Mammal \n",
            "chicken: Bird \n",
            "chub: Mammal  Fish\n",
            "clam: Mammal  Invertebrate\n",
            "crab: Mammal  Invertebrate\n",
            "crayfish: Mammal  Invertebrate\n",
            "crow: Bird \n",
            "deer: Mammal \n",
            "dogfish: Mammal  Fish\n",
            "dolphin: Mammal \n",
            "dove: Bird \n",
            "duck: Bird \n",
            "elephant: Mammal \n",
            "flamingo: Bird \n",
            "flea: Mammal  Bug\n",
            "frog: Mammal  Amphibian\n",
            "\n",
            "***Model 1 Predictions:***\n",
            "frog: Mammal  Amphibian\n",
            "fruitbat: Mammal \n",
            "giraffe: Mammal \n",
            "girl: Mammal \n",
            "gnat: Bird  Bug\n",
            "goat: Mammal \n",
            "gorilla: Mammal \n",
            "gull: Bird \n",
            "haddock: Mammal  Fish\n",
            "hamster: Mammal \n",
            "hare: Mammal \n",
            "hawk: Bird \n",
            "herring: Mammal  Fish\n",
            "honeybee: Mammal  Bug\n",
            "housefly: Mammal  Bug\n",
            "kiwi: Bird \n",
            "ladybird: Bird  Bug\n",
            "lark: Bird \n",
            "leopard: Mammal \n",
            "lion: Mammal \n",
            "lobster: Bird  Invertebrate\n",
            "lynx: Mammal \n",
            "mink: Mammal \n",
            "mole: Mammal \n",
            "mongoose: Mammal \n",
            "\n",
            "***Model 2 Predictions:***\n",
            "moth: Mammal  Bug\n",
            "newt: Mammal  Amphibian\n",
            "octopus: Mammal  Invertebrate\n",
            "opossum: Mammal \n",
            "oryx: Mammal \n",
            "ostrich: Mammal  Bird\n",
            "parakeet: Bird \n",
            "penguin: Mammal  Bird\n",
            "pheasant: Bird \n",
            "pike: Mammal  Fish\n",
            "piranha: Mammal  Fish\n",
            "pitviper: Mammal  Reptile\n",
            "platypus: Mammal \n",
            "polecat: Mammal \n",
            "pony: Mammal \n",
            "porpoise: Mammal \n",
            "puma: Mammal \n",
            "pussycat: Mammal \n",
            "raccoon: Mammal \n",
            "reindeer: Mammal \n",
            "rhea: Mammal  Bird\n",
            "scorpion: Mammal  Invertebrate\n",
            "seahorse: Mammal  Fish\n",
            "seal: Mammal \n",
            "sealion: Mammal \n",
            "\n",
            "***Model 3 Predictions:***\n",
            "seasnake: Mammal  Reptile\n",
            "seawasp: Bird  Invertebrate\n",
            "skimmer: Bird \n",
            "skua: Bird \n",
            "slowworm: Mammal  Reptile\n",
            "slug: Mammal  Invertebrate\n",
            "sole: Mammal  Fish\n",
            "sparrow: Bird \n",
            "squirrel: Mammal \n",
            "starfish: Mammal  Invertebrate\n",
            "stingray: Mammal  Fish\n",
            "swan: Mammal  Bird\n",
            "termite: Mammal  Bug\n",
            "toad: Mammal  Amphibian\n",
            "tortoise: Mammal  Reptile\n",
            "tuatara: Mammal  Reptile\n",
            "tuna: Mammal  Fish\n",
            "vampire: Mammal \n",
            "vole: Mammal \n",
            "vulture: Mammal  Bird\n",
            "wallaby: Mammal \n",
            "wasp: Mammal  Bug\n",
            "wolf: Mammal \n",
            "worm: Mammal  Invertebrate\n",
            "wren: Bird \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nb2_preds.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Bayes III"
      ],
      "metadata": {
        "id": "Pmbj_bRXCxUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb3_preds = []\n",
        "\n",
        "for i, model in enumerate(nb3_models):\n",
        "  test_data = split_data[i]['test_data']\n",
        "  test_labels = split_data[i]['test_labels']\n",
        "  preds = model.predict(test_data)\n",
        "  nb3_preds.append(preds)\n",
        "\n",
        "  print(f'***Model {i} Predictions:***')\n",
        "  for j, animal_idx in enumerate(test_data.index):\n",
        "    animal_name = animals.iloc[animal_idx,0]\n",
        "    predicted_class = preds[j]\n",
        "    actual_class = test_labels.iloc[j]\n",
        "    correct = predicted_class == actual_class\n",
        "    if (correct):\n",
        "      print(animal_name + \": \" + class_dict[predicted_class] + \" \")\n",
        "    else:\n",
        "      print(animal_name + \": \" + class_dict[predicted_class] + \"  \" + class_dict[actual_class])\n",
        "  print()\n",
        "\n",
        "joblib.dump(nb3_preds, 'nb3_preds.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvWq3nWcplw-",
        "outputId": "7ca3d18e-e843-439d-fdf3-d5a84af68ea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***Model 0 Predictions:***\n",
            "aardvark: Mammal \n",
            "antelope: Mammal \n",
            "bass: Fish \n",
            "bear: Mammal \n",
            "boar: Mammal \n",
            "buffalo: Mammal \n",
            "calf: Mammal \n",
            "carp: Fish \n",
            "catfish: Fish \n",
            "cavy: Mammal \n",
            "cheetah: Mammal \n",
            "chicken: Bird \n",
            "chub: Fish \n",
            "clam: Invertebrate \n",
            "crab: Invertebrate \n",
            "crayfish: Invertebrate \n",
            "crow: Bird \n",
            "deer: Mammal \n",
            "dogfish: Fish \n",
            "dolphin: Fish  Mammal\n",
            "dove: Bird \n",
            "duck: Bird \n",
            "elephant: Mammal \n",
            "flamingo: Bird \n",
            "flea: Bug \n",
            "frog: Amphibian \n",
            "\n",
            "***Model 1 Predictions:***\n",
            "frog: Amphibian \n",
            "fruitbat: Mammal \n",
            "giraffe: Mammal \n",
            "girl: Mammal \n",
            "gnat: Bug \n",
            "goat: Mammal \n",
            "gorilla: Mammal \n",
            "gull: Bird \n",
            "haddock: Fish \n",
            "hamster: Mammal \n",
            "hare: Mammal \n",
            "hawk: Bird \n",
            "herring: Fish \n",
            "honeybee: Bug \n",
            "housefly: Bug \n",
            "kiwi: Bird \n",
            "ladybird: Bug \n",
            "lark: Bird \n",
            "leopard: Mammal \n",
            "lion: Mammal \n",
            "lobster: Invertebrate \n",
            "lynx: Mammal \n",
            "mink: Mammal \n",
            "mole: Mammal \n",
            "mongoose: Mammal \n",
            "\n",
            "***Model 2 Predictions:***\n",
            "moth: Bug \n",
            "newt: Amphibian \n",
            "octopus: Invertebrate \n",
            "opossum: Mammal \n",
            "oryx: Mammal \n",
            "ostrich: Bird \n",
            "parakeet: Bird \n",
            "penguin: Bird \n",
            "pheasant: Bird \n",
            "pike: Fish \n",
            "piranha: Fish \n",
            "pitviper: Reptile \n",
            "platypus: Reptile  Mammal\n",
            "polecat: Mammal \n",
            "pony: Mammal \n",
            "porpoise: Fish  Mammal\n",
            "puma: Mammal \n",
            "pussycat: Mammal \n",
            "raccoon: Mammal \n",
            "reindeer: Mammal \n",
            "rhea: Bird \n",
            "scorpion: Reptile  Invertebrate\n",
            "seahorse: Fish \n",
            "seal: Mammal \n",
            "sealion: Mammal \n",
            "\n",
            "***Model 3 Predictions:***\n",
            "seasnake: Reptile \n",
            "seawasp: Invertebrate \n",
            "skimmer: Bird \n",
            "skua: Bird \n",
            "slowworm: Reptile \n",
            "slug: Bug  Invertebrate\n",
            "sole: Fish \n",
            "sparrow: Bird \n",
            "squirrel: Mammal \n",
            "starfish: Invertebrate \n",
            "stingray: Fish \n",
            "swan: Bird \n",
            "termite: Bug \n",
            "toad: Amphibian \n",
            "tortoise: Bird  Reptile\n",
            "tuatara: Amphibian  Reptile\n",
            "tuna: Fish \n",
            "vampire: Mammal \n",
            "vole: Mammal \n",
            "vulture: Bird \n",
            "wallaby: Mammal \n",
            "wasp: Bug \n",
            "wolf: Mammal \n",
            "worm: Bug  Invertebrate\n",
            "wren: Bird \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nb3_preds.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression I"
      ],
      "metadata": {
        "id": "ppc-z4MQ_3k2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr1_preds = []\n",
        "\n",
        "for i, model in enumerate(lr1_models):\n",
        "  test_data = split_data[i]['test_data']\n",
        "  test_labels = split_data[i]['test_labels']\n",
        "  preds = model.predict(test_data)\n",
        "  lr1_preds.append(preds)\n",
        "\n",
        "  print(f'***Model {i} Predictions:***')\n",
        "  for j, animal_idx in enumerate(test_data.index):\n",
        "    animal_name = animals.iloc[animal_idx,0]\n",
        "    predicted_class = preds[j]\n",
        "    actual_class = test_labels.iloc[j]\n",
        "    correct = predicted_class == actual_class\n",
        "    if (correct):\n",
        "      print(animal_name + \": \" + class_dict[predicted_class] + \" \")\n",
        "    else:\n",
        "      print(animal_name + \": \" + class_dict[predicted_class] + \"  \" + class_dict[actual_class])\n",
        "  print()\n",
        "\n",
        "joblib.dump(lr1_preds, 'lr1_preds.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hy5t8RTRJpS2",
        "outputId": "032b3b64-1bdf-4101-b062-31da8b41aaf1"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***Model 0 Predictions:***\n",
            "aardvark: Mammal \n",
            "antelope: Mammal \n",
            "bass: Fish \n",
            "bear: Mammal \n",
            "boar: Mammal \n",
            "buffalo: Mammal \n",
            "calf: Mammal \n",
            "carp: Fish \n",
            "catfish: Fish \n",
            "cavy: Mammal \n",
            "cheetah: Mammal \n",
            "chicken: Bird \n",
            "chub: Fish \n",
            "clam: Invertebrate \n",
            "crab: Invertebrate \n",
            "crayfish: Invertebrate \n",
            "crow: Bird \n",
            "deer: Mammal \n",
            "dogfish: Fish \n",
            "dolphin: Mammal \n",
            "dove: Bird \n",
            "duck: Bird \n",
            "elephant: Mammal \n",
            "flamingo: Bird \n",
            "flea: Bug \n",
            "frog: Amphibian \n",
            "\n",
            "***Model 1 Predictions:***\n",
            "frog: Amphibian \n",
            "fruitbat: Mammal \n",
            "giraffe: Mammal \n",
            "girl: Mammal \n",
            "gnat: Bug \n",
            "goat: Mammal \n",
            "gorilla: Mammal \n",
            "gull: Bird \n",
            "haddock: Fish \n",
            "hamster: Mammal \n",
            "hare: Mammal \n",
            "hawk: Bird \n",
            "herring: Fish \n",
            "honeybee: Bug \n",
            "housefly: Bug \n",
            "kiwi: Bird \n",
            "ladybird: Bug \n",
            "lark: Bird \n",
            "leopard: Mammal \n",
            "lion: Mammal \n",
            "lobster: Invertebrate \n",
            "lynx: Mammal \n",
            "mink: Mammal \n",
            "mole: Mammal \n",
            "mongoose: Mammal \n",
            "\n",
            "***Model 2 Predictions:***\n",
            "moth: Bug \n",
            "newt: Amphibian \n",
            "octopus: Bug  Invertebrate\n",
            "opossum: Mammal \n",
            "oryx: Mammal \n",
            "ostrich: Bird \n",
            "parakeet: Bird \n",
            "penguin: Bird \n",
            "pheasant: Bird \n",
            "pike: Fish \n",
            "piranha: Fish \n",
            "pitviper: Reptile \n",
            "platypus: Mammal \n",
            "polecat: Mammal \n",
            "pony: Mammal \n",
            "porpoise: Mammal \n",
            "puma: Mammal \n",
            "pussycat: Mammal \n",
            "raccoon: Mammal \n",
            "reindeer: Mammal \n",
            "rhea: Bird \n",
            "scorpion: Bug  Invertebrate\n",
            "seahorse: Fish \n",
            "seal: Mammal \n",
            "sealion: Mammal \n",
            "\n",
            "***Model 3 Predictions:***\n",
            "seasnake: Fish  Reptile\n",
            "seawasp: Invertebrate \n",
            "skimmer: Bird \n",
            "skua: Bird \n",
            "slowworm: Fish  Reptile\n",
            "slug: Bird  Invertebrate\n",
            "sole: Fish \n",
            "sparrow: Bird \n",
            "squirrel: Mammal \n",
            "starfish: Invertebrate \n",
            "stingray: Fish \n",
            "swan: Bird \n",
            "termite: Bug \n",
            "toad: Amphibian \n",
            "tortoise: Bird  Reptile\n",
            "tuatara: Amphibian  Reptile\n",
            "tuna: Fish \n",
            "vampire: Mammal \n",
            "vole: Mammal \n",
            "vulture: Bird \n",
            "wallaby: Mammal \n",
            "wasp: Bug \n",
            "wolf: Mammal \n",
            "worm: Bird  Invertebrate\n",
            "wren: Bird \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['lr1_preds.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression II"
      ],
      "metadata": {
        "id": "cSepwnKhC15S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr2_preds = []\n",
        "\n",
        "for i, model in enumerate(lr2_models):\n",
        "  test_data = split_data[i]['test_data']\n",
        "  test_labels = split_data[i]['test_labels']\n",
        "  preds = model.predict(test_data)\n",
        "  lr2_preds.append(preds)\n",
        "\n",
        "  print(f'***Model {i} Predictions:***')\n",
        "  for j, animal_idx in enumerate(test_data.index):\n",
        "    animal_name = animals.iloc[animal_idx,0]\n",
        "    predicted_class = preds[j]\n",
        "    actual_class = test_labels.iloc[j]\n",
        "    correct = predicted_class == actual_class\n",
        "    if (correct):\n",
        "      print(animal_name + \": \" + class_dict[predicted_class] + \" \")\n",
        "    else:\n",
        "      print(animal_name + \": \" + class_dict[predicted_class] + \"  \" + class_dict[actual_class])\n",
        "  print()\n",
        "\n",
        "joblib.dump(lr2_preds, 'lr2_preds.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cY0xODhXJwoD",
        "outputId": "3d0de1ee-3a50-4817-8983-90bebc5fc1a4"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***Model 0 Predictions:***\n",
            "aardvark: Mammal \n",
            "antelope: Mammal \n",
            "bass: Fish \n",
            "bear: Mammal \n",
            "boar: Mammal \n",
            "buffalo: Mammal \n",
            "calf: Mammal \n",
            "carp: Fish \n",
            "catfish: Fish \n",
            "cavy: Mammal \n",
            "cheetah: Mammal \n",
            "chicken: Bird \n",
            "chub: Fish \n",
            "clam: Invertebrate \n",
            "crab: Invertebrate \n",
            "crayfish: Invertebrate \n",
            "crow: Bird \n",
            "deer: Mammal \n",
            "dogfish: Fish \n",
            "dolphin: Mammal \n",
            "dove: Bird \n",
            "duck: Bird \n",
            "elephant: Mammal \n",
            "flamingo: Bird \n",
            "flea: Bug \n",
            "frog: Amphibian \n",
            "\n",
            "***Model 1 Predictions:***\n",
            "frog: Amphibian \n",
            "fruitbat: Mammal \n",
            "giraffe: Mammal \n",
            "girl: Mammal \n",
            "gnat: Bug \n",
            "goat: Mammal \n",
            "gorilla: Mammal \n",
            "gull: Bird \n",
            "haddock: Fish \n",
            "hamster: Mammal \n",
            "hare: Mammal \n",
            "hawk: Bird \n",
            "herring: Fish \n",
            "honeybee: Bug \n",
            "housefly: Bug \n",
            "kiwi: Bird \n",
            "ladybird: Bug \n",
            "lark: Bird \n",
            "leopard: Mammal \n",
            "lion: Mammal \n",
            "lobster: Invertebrate \n",
            "lynx: Mammal \n",
            "mink: Mammal \n",
            "mole: Mammal \n",
            "mongoose: Mammal \n",
            "\n",
            "***Model 2 Predictions:***\n",
            "moth: Bug \n",
            "newt: Amphibian \n",
            "octopus: Bug  Invertebrate\n",
            "opossum: Mammal \n",
            "oryx: Mammal \n",
            "ostrich: Bird \n",
            "parakeet: Bird \n",
            "penguin: Bird \n",
            "pheasant: Bird \n",
            "pike: Fish \n",
            "piranha: Fish \n",
            "pitviper: Reptile \n",
            "platypus: Mammal \n",
            "polecat: Mammal \n",
            "pony: Mammal \n",
            "porpoise: Mammal \n",
            "puma: Mammal \n",
            "pussycat: Mammal \n",
            "raccoon: Mammal \n",
            "reindeer: Mammal \n",
            "rhea: Bird \n",
            "scorpion: Bug  Invertebrate\n",
            "seahorse: Fish \n",
            "seal: Mammal \n",
            "sealion: Mammal \n",
            "\n",
            "***Model 3 Predictions:***\n",
            "seasnake: Fish  Reptile\n",
            "seawasp: Invertebrate \n",
            "skimmer: Bird \n",
            "skua: Bird \n",
            "slowworm: Fish  Reptile\n",
            "slug: Bird  Invertebrate\n",
            "sole: Fish \n",
            "sparrow: Bird \n",
            "squirrel: Mammal \n",
            "starfish: Invertebrate \n",
            "stingray: Fish \n",
            "swan: Bird \n",
            "termite: Bug \n",
            "toad: Amphibian \n",
            "tortoise: Bird  Reptile\n",
            "tuatara: Amphibian  Reptile\n",
            "tuna: Fish \n",
            "vampire: Mammal \n",
            "vole: Mammal \n",
            "vulture: Bird \n",
            "wallaby: Mammal \n",
            "wasp: Bug \n",
            "wolf: Mammal \n",
            "worm: Bird  Invertebrate\n",
            "wren: Bird \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['lr2_preds.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression III"
      ],
      "metadata": {
        "id": "HLBu3hDCC2Ey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr3_preds = []\n",
        "\n",
        "for i, model in enumerate(lr3_models):\n",
        "  test_data = split_data[i]['test_data']\n",
        "  test_labels = split_data[i]['test_labels']\n",
        "  preds = model.predict(test_data)\n",
        "  lr3_preds.append(preds)\n",
        "\n",
        "  print(f'***Model {i} Predictions:***')\n",
        "  for j, animal_idx in enumerate(test_data.index):\n",
        "    animal_name = animals.iloc[animal_idx,0]\n",
        "    predicted_class = preds[j]\n",
        "    actual_class = test_labels.iloc[j]\n",
        "    correct = predicted_class == actual_class\n",
        "    if (correct):\n",
        "      print(animal_name + \": \" + class_dict[predicted_class] + \" \")\n",
        "    else:\n",
        "      print(animal_name + \": \" + class_dict[predicted_class] + \"  \" + class_dict[actual_class])\n",
        "  print()\n",
        "\n",
        "joblib.dump(lr3_preds, 'lr3_preds.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYVYnR4xJ1qd",
        "outputId": "148e1296-bc04-4ac4-a978-62f93f29fc7d"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***Model 0 Predictions:***\n",
            "aardvark: Mammal \n",
            "antelope: Mammal \n",
            "bass: Mammal  Fish\n",
            "bear: Mammal \n",
            "boar: Mammal \n",
            "buffalo: Mammal \n",
            "calf: Mammal \n",
            "carp: Mammal  Fish\n",
            "catfish: Mammal  Fish\n",
            "cavy: Mammal \n",
            "cheetah: Mammal \n",
            "chicken: Mammal  Bird\n",
            "chub: Mammal  Fish\n",
            "clam: Mammal  Invertebrate\n",
            "crab: Mammal  Invertebrate\n",
            "crayfish: Mammal  Invertebrate\n",
            "crow: Mammal  Bird\n",
            "deer: Mammal \n",
            "dogfish: Mammal  Fish\n",
            "dolphin: Mammal \n",
            "dove: Mammal  Bird\n",
            "duck: Mammal  Bird\n",
            "elephant: Mammal \n",
            "flamingo: Mammal  Bird\n",
            "flea: Mammal  Bug\n",
            "frog: Mammal  Amphibian\n",
            "\n",
            "***Model 1 Predictions:***\n",
            "frog: Mammal  Amphibian\n",
            "fruitbat: Mammal \n",
            "giraffe: Mammal \n",
            "girl: Mammal \n",
            "gnat: Mammal  Bug\n",
            "goat: Mammal \n",
            "gorilla: Mammal \n",
            "gull: Bird \n",
            "haddock: Fish \n",
            "hamster: Mammal \n",
            "hare: Mammal \n",
            "hawk: Bird \n",
            "herring: Fish \n",
            "honeybee: Mammal  Bug\n",
            "housefly: Mammal  Bug\n",
            "kiwi: Mammal  Bird\n",
            "ladybird: Mammal  Bug\n",
            "lark: Bird \n",
            "leopard: Mammal \n",
            "lion: Mammal \n",
            "lobster: Mammal  Invertebrate\n",
            "lynx: Mammal \n",
            "mink: Mammal \n",
            "mole: Mammal \n",
            "mongoose: Mammal \n",
            "\n",
            "***Model 2 Predictions:***\n",
            "moth: Mammal  Bug\n",
            "newt: Mammal  Amphibian\n",
            "octopus: Mammal  Invertebrate\n",
            "opossum: Mammal \n",
            "oryx: Mammal \n",
            "ostrich: Mammal  Bird\n",
            "parakeet: Bird \n",
            "penguin: Mammal  Bird\n",
            "pheasant: Bird \n",
            "pike: Mammal  Fish\n",
            "piranha: Fish \n",
            "pitviper: Mammal  Reptile\n",
            "platypus: Mammal \n",
            "polecat: Mammal \n",
            "pony: Mammal \n",
            "porpoise: Mammal \n",
            "puma: Mammal \n",
            "pussycat: Mammal \n",
            "raccoon: Mammal \n",
            "reindeer: Mammal \n",
            "rhea: Mammal  Bird\n",
            "scorpion: Mammal  Invertebrate\n",
            "seahorse: Fish \n",
            "seal: Mammal \n",
            "sealion: Mammal \n",
            "\n",
            "***Model 3 Predictions:***\n",
            "seasnake: Mammal  Reptile\n",
            "seawasp: Mammal  Invertebrate\n",
            "skimmer: Mammal  Bird\n",
            "skua: Mammal  Bird\n",
            "slowworm: Mammal  Reptile\n",
            "slug: Mammal  Invertebrate\n",
            "sole: Mammal  Fish\n",
            "sparrow: Mammal  Bird\n",
            "squirrel: Mammal \n",
            "starfish: Mammal  Invertebrate\n",
            "stingray: Mammal  Fish\n",
            "swan: Mammal  Bird\n",
            "termite: Mammal  Bug\n",
            "toad: Mammal  Amphibian\n",
            "tortoise: Mammal  Reptile\n",
            "tuatara: Mammal  Reptile\n",
            "tuna: Mammal  Fish\n",
            "vampire: Mammal \n",
            "vole: Mammal \n",
            "vulture: Mammal  Bird\n",
            "wallaby: Mammal \n",
            "wasp: Mammal  Bug\n",
            "wolf: Mammal \n",
            "worm: Mammal  Invertebrate\n",
            "wren: Mammal  Bird\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['lr3_preds.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-Layer Perceptron I"
      ],
      "metadata": {
        "id": "dRel2XbS_3vZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp1_preds = []\n",
        "\n",
        "for i, model in enumerate(mlp1_models):\n",
        "  test_data = split_data[i]['test_data']\n",
        "  test_labels = split_data[i]['test_labels']\n",
        "  preds = model.predict(test_data)\n",
        "  mlp1_preds.append(preds)\n",
        "\n",
        "  print(f'***Model {i} Predictions:***')\n",
        "  for j, animal_idx in enumerate(test_data.index):\n",
        "    animal_name = animals.iloc[animal_idx,0]\n",
        "    predicted_class = preds[j]\n",
        "    actual_class = test_labels.iloc[j]\n",
        "    correct = predicted_class == actual_class\n",
        "    if (correct):\n",
        "      print(animal_name + \": \" + class_dict[predicted_class] + \" \")\n",
        "    else:\n",
        "      print(animal_name + \": \" + class_dict[predicted_class] + \"  \" + class_dict[actual_class])\n",
        "  print()\n",
        "\n",
        "joblib.dump(mlp1_preds, 'mlp1_preds.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1B5qwYhaDDD0",
        "outputId": "ab159611-8619-4904-f8e7-d98ae85ef091"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***Model 0 Predictions:***\n",
            "aardvark: Mammal \n",
            "antelope: Mammal \n",
            "bass: Fish \n",
            "bear: Mammal \n",
            "boar: Mammal \n",
            "buffalo: Mammal \n",
            "calf: Mammal \n",
            "carp: Fish \n",
            "catfish: Fish \n",
            "cavy: Mammal \n",
            "cheetah: Mammal \n",
            "chicken: Bird \n",
            "chub: Fish \n",
            "clam: Invertebrate \n",
            "crab: Invertebrate \n",
            "crayfish: Invertebrate \n",
            "crow: Bird \n",
            "deer: Mammal \n",
            "dogfish: Fish \n",
            "dolphin: Mammal \n",
            "dove: Bird \n",
            "duck: Bird \n",
            "elephant: Mammal \n",
            "flamingo: Bird \n",
            "flea: Bug \n",
            "frog: Amphibian \n",
            "\n",
            "***Model 1 Predictions:***\n",
            "frog: Amphibian \n",
            "fruitbat: Mammal \n",
            "giraffe: Mammal \n",
            "girl: Mammal \n",
            "gnat: Bug \n",
            "goat: Mammal \n",
            "gorilla: Mammal \n",
            "gull: Bird \n",
            "haddock: Fish \n",
            "hamster: Mammal \n",
            "hare: Mammal \n",
            "hawk: Bird \n",
            "herring: Fish \n",
            "honeybee: Bug \n",
            "housefly: Bug \n",
            "kiwi: Bird \n",
            "ladybird: Bug \n",
            "lark: Bird \n",
            "leopard: Mammal \n",
            "lion: Mammal \n",
            "lobster: Invertebrate \n",
            "lynx: Mammal \n",
            "mink: Mammal \n",
            "mole: Mammal \n",
            "mongoose: Mammal \n",
            "\n",
            "***Model 2 Predictions:***\n",
            "moth: Bug \n",
            "newt: Amphibian \n",
            "octopus: Invertebrate \n",
            "opossum: Mammal \n",
            "oryx: Mammal \n",
            "ostrich: Bird \n",
            "parakeet: Bird \n",
            "penguin: Bird \n",
            "pheasant: Bird \n",
            "pike: Fish \n",
            "piranha: Fish \n",
            "pitviper: Reptile \n",
            "platypus: Mammal \n",
            "polecat: Mammal \n",
            "pony: Mammal \n",
            "porpoise: Mammal \n",
            "puma: Mammal \n",
            "pussycat: Mammal \n",
            "raccoon: Mammal \n",
            "reindeer: Mammal \n",
            "rhea: Bird \n",
            "scorpion: Bug  Invertebrate\n",
            "seahorse: Fish \n",
            "seal: Mammal \n",
            "sealion: Mammal \n",
            "\n",
            "***Model 3 Predictions:***\n",
            "seasnake: Fish  Reptile\n",
            "seawasp: Invertebrate \n",
            "skimmer: Bird \n",
            "skua: Bird \n",
            "slowworm: Reptile \n",
            "slug: Bird  Invertebrate\n",
            "sole: Fish \n",
            "sparrow: Bird \n",
            "squirrel: Mammal \n",
            "starfish: Invertebrate \n",
            "stingray: Fish \n",
            "swan: Bird \n",
            "termite: Bug \n",
            "toad: Amphibian \n",
            "tortoise: Bird  Reptile\n",
            "tuatara: Amphibian  Reptile\n",
            "tuna: Fish \n",
            "vampire: Mammal \n",
            "vole: Mammal \n",
            "vulture: Bird \n",
            "wallaby: Mammal \n",
            "wasp: Bug \n",
            "wolf: Mammal \n",
            "worm: Bird  Invertebrate\n",
            "wren: Bird \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mlp1_preds.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-Layer Perceptron II"
      ],
      "metadata": {
        "id": "Xs5jIqvZC4j_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp2_preds = []\n",
        "\n",
        "for i, model in enumerate(mlp2_models):\n",
        "  test_data = split_data[i]['test_data']\n",
        "  test_labels = split_data[i]['test_labels']\n",
        "  preds = model.predict(test_data)\n",
        "  mlp2_preds.append(preds)\n",
        "\n",
        "  print(f'***Model {i} Predictions:***')\n",
        "  for j, animal_idx in enumerate(test_data.index):\n",
        "    animal_name = animals.iloc[animal_idx,0]\n",
        "    predicted_class = preds[j]\n",
        "    actual_class = test_labels.iloc[j]\n",
        "    correct = predicted_class == actual_class\n",
        "    if (correct):\n",
        "      print(animal_name + \": \" + class_dict[predicted_class] + \" \")\n",
        "    else:\n",
        "      print(animal_name + \": \" + class_dict[predicted_class] + \"  \" + class_dict[actual_class])\n",
        "  print()\n",
        "\n",
        "joblib.dump(mlp2_preds, 'mlp2_preds.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQ0KKgwHDOcU",
        "outputId": "512bc97a-ade6-4676-f3f6-8050578e3e11"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***Model 0 Predictions:***\n",
            "aardvark: Mammal \n",
            "antelope: Mammal \n",
            "bass: Fish \n",
            "bear: Mammal \n",
            "boar: Mammal \n",
            "buffalo: Mammal \n",
            "calf: Mammal \n",
            "carp: Fish \n",
            "catfish: Fish \n",
            "cavy: Mammal \n",
            "cheetah: Mammal \n",
            "chicken: Bird \n",
            "chub: Fish \n",
            "clam: Invertebrate \n",
            "crab: Invertebrate \n",
            "crayfish: Invertebrate \n",
            "crow: Bird \n",
            "deer: Mammal \n",
            "dogfish: Fish \n",
            "dolphin: Mammal \n",
            "dove: Bird \n",
            "duck: Bird \n",
            "elephant: Mammal \n",
            "flamingo: Bird \n",
            "flea: Bug \n",
            "frog: Amphibian \n",
            "\n",
            "***Model 1 Predictions:***\n",
            "frog: Amphibian \n",
            "fruitbat: Mammal \n",
            "giraffe: Mammal \n",
            "girl: Mammal \n",
            "gnat: Bug \n",
            "goat: Mammal \n",
            "gorilla: Mammal \n",
            "gull: Bird \n",
            "haddock: Fish \n",
            "hamster: Mammal \n",
            "hare: Mammal \n",
            "hawk: Bird \n",
            "herring: Fish \n",
            "honeybee: Bug \n",
            "housefly: Bug \n",
            "kiwi: Bird \n",
            "ladybird: Bug \n",
            "lark: Bird \n",
            "leopard: Mammal \n",
            "lion: Mammal \n",
            "lobster: Invertebrate \n",
            "lynx: Mammal \n",
            "mink: Mammal \n",
            "mole: Mammal \n",
            "mongoose: Mammal \n",
            "\n",
            "***Model 2 Predictions:***\n",
            "moth: Bug \n",
            "newt: Reptile  Amphibian\n",
            "octopus: Invertebrate \n",
            "opossum: Mammal \n",
            "oryx: Mammal \n",
            "ostrich: Bird \n",
            "parakeet: Bird \n",
            "penguin: Reptile  Bird\n",
            "pheasant: Bird \n",
            "pike: Fish \n",
            "piranha: Fish \n",
            "pitviper: Reptile \n",
            "platypus: Mammal \n",
            "polecat: Mammal \n",
            "pony: Mammal \n",
            "porpoise: Mammal \n",
            "puma: Mammal \n",
            "pussycat: Mammal \n",
            "raccoon: Mammal \n",
            "reindeer: Mammal \n",
            "rhea: Bird \n",
            "scorpion: Bug  Invertebrate\n",
            "seahorse: Fish \n",
            "seal: Mammal \n",
            "sealion: Mammal \n",
            "\n",
            "***Model 3 Predictions:***\n",
            "seasnake: Fish  Reptile\n",
            "seawasp: Invertebrate \n",
            "skimmer: Bird \n",
            "skua: Bird \n",
            "slowworm: Reptile \n",
            "slug: Bird  Invertebrate\n",
            "sole: Fish \n",
            "sparrow: Bird \n",
            "squirrel: Mammal \n",
            "starfish: Invertebrate \n",
            "stingray: Fish \n",
            "swan: Bird \n",
            "termite: Bug \n",
            "toad: Amphibian \n",
            "tortoise: Bug  Reptile\n",
            "tuatara: Amphibian  Reptile\n",
            "tuna: Fish \n",
            "vampire: Mammal \n",
            "vole: Mammal \n",
            "vulture: Bird \n",
            "wallaby: Mammal \n",
            "wasp: Bug \n",
            "wolf: Mammal \n",
            "worm: Bird  Invertebrate\n",
            "wren: Bird \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mlp2_preds.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-Layer Perceptron III"
      ],
      "metadata": {
        "id": "lXMxSEn3C4rE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp3_preds = []\n",
        "\n",
        "for i, model in enumerate(mlp3_models):\n",
        "  test_data = split_data[i]['test_data']\n",
        "  test_labels = split_data[i]['test_labels']\n",
        "  preds = model.predict(test_data)\n",
        "  mlp3_preds.append(preds)\n",
        "\n",
        "  print(f'***Model {i} Predictions:***')\n",
        "  for j, animal_idx in enumerate(test_data.index):\n",
        "    animal_name = animals.iloc[animal_idx,0]\n",
        "    predicted_class = preds[j]\n",
        "    actual_class = test_labels.iloc[j]\n",
        "    correct = predicted_class == actual_class\n",
        "    if (correct):\n",
        "      print(animal_name + \": \" + class_dict[predicted_class] + \" \")\n",
        "    else:\n",
        "      print(animal_name + \": \" + class_dict[predicted_class] + \"  \" + class_dict[actual_class])\n",
        "  print()\n",
        "\n",
        "joblib.dump(mlp3_preds, 'mlp3_preds.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXp-3lCsDWYK",
        "outputId": "ecb76500-777a-4e0b-c558-9ce3996bc768"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***Model 0 Predictions:***\n",
            "aardvark: Mammal \n",
            "antelope: Mammal \n",
            "bass: Fish \n",
            "bear: Mammal \n",
            "boar: Mammal \n",
            "buffalo: Mammal \n",
            "calf: Mammal \n",
            "carp: Fish \n",
            "catfish: Fish \n",
            "cavy: Mammal \n",
            "cheetah: Mammal \n",
            "chicken: Bird \n",
            "chub: Fish \n",
            "clam: Invertebrate \n",
            "crab: Invertebrate \n",
            "crayfish: Invertebrate \n",
            "crow: Bird \n",
            "deer: Mammal \n",
            "dogfish: Fish \n",
            "dolphin: Mammal \n",
            "dove: Bird \n",
            "duck: Bird \n",
            "elephant: Mammal \n",
            "flamingo: Bird \n",
            "flea: Bug \n",
            "frog: Amphibian \n",
            "\n",
            "***Model 1 Predictions:***\n",
            "frog: Bug  Amphibian\n",
            "fruitbat: Mammal \n",
            "giraffe: Mammal \n",
            "girl: Mammal \n",
            "gnat: Bug \n",
            "goat: Mammal \n",
            "gorilla: Mammal \n",
            "gull: Bird \n",
            "haddock: Fish \n",
            "hamster: Mammal \n",
            "hare: Mammal \n",
            "hawk: Bird \n",
            "herring: Fish \n",
            "honeybee: Bug \n",
            "housefly: Bug \n",
            "kiwi: Bird \n",
            "ladybird: Bug \n",
            "lark: Bird \n",
            "leopard: Mammal \n",
            "lion: Mammal \n",
            "lobster: Invertebrate \n",
            "lynx: Mammal \n",
            "mink: Mammal \n",
            "mole: Mammal \n",
            "mongoose: Mammal \n",
            "\n",
            "***Model 2 Predictions:***\n",
            "moth: Bug \n",
            "newt: Reptile  Amphibian\n",
            "octopus: Invertebrate \n",
            "opossum: Mammal \n",
            "oryx: Mammal \n",
            "ostrich: Bird \n",
            "parakeet: Bird \n",
            "penguin: Mammal  Bird\n",
            "pheasant: Bird \n",
            "pike: Fish \n",
            "piranha: Fish \n",
            "pitviper: Reptile \n",
            "platypus: Bird  Mammal\n",
            "polecat: Mammal \n",
            "pony: Mammal \n",
            "porpoise: Mammal \n",
            "puma: Mammal \n",
            "pussycat: Mammal \n",
            "raccoon: Mammal \n",
            "reindeer: Mammal \n",
            "rhea: Bird \n",
            "scorpion: Invertebrate \n",
            "seahorse: Fish \n",
            "seal: Mammal \n",
            "sealion: Mammal \n",
            "\n",
            "***Model 3 Predictions:***\n",
            "seasnake: Fish  Reptile\n",
            "seawasp: Fish  Invertebrate\n",
            "skimmer: Bird \n",
            "skua: Bird \n",
            "slowworm: Reptile \n",
            "slug: Invertebrate \n",
            "sole: Fish \n",
            "sparrow: Bird \n",
            "squirrel: Mammal \n",
            "starfish: Invertebrate \n",
            "stingray: Fish \n",
            "swan: Bird \n",
            "termite: Bug \n",
            "toad: Amphibian \n",
            "tortoise: Invertebrate  Reptile\n",
            "tuatara: Bug  Reptile\n",
            "tuna: Fish \n",
            "vampire: Mammal \n",
            "vole: Mammal \n",
            "vulture: Bird \n",
            "wallaby: Mammal \n",
            "wasp: Bug \n",
            "wolf: Mammal \n",
            "worm: Invertebrate \n",
            "wren: Bird \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mlp3_preds.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Perform evaluation with precision / recall"
      ],
      "metadata": {
        "id": "qn1qi27Q-J_h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Bayes I"
      ],
      "metadata": {
        "id": "eVQlogFiAXJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "nb1_scores = []\n",
        "\n",
        "for i, preds in enumerate(nb1_preds):\n",
        "  target = split_data[i]['test_labels']\n",
        "  (precision,recall,_,_) = precision_recall_fscore_support(\n",
        "      target, \n",
        "      preds, \n",
        "      average='macro', \n",
        "      zero_division=0)\n",
        "  precision = round(precision,3)\n",
        "  recall = round(recall,3)\n",
        "  nb1_scores.append((precision, recall))\n",
        "  print(f'***Model {i} Score:***')\n",
        "  print(f'Precision: {precision}')\n",
        "  print(f'Recall {recall}')\n",
        "  print()\n",
        "\n",
        "nb1_avg_precision = sum([p for (p,_) in nb1_scores]) / len(nb1_scores)\n",
        "nb1_avg_recall = sum([r for (_,r) in nb1_scores]) / len(nb1_scores)\n",
        "print('***AVERAGE***')\n",
        "print(f'Precision: {round(nb1_avg_precision,3)}')\n",
        "print(f'Recall: {round(nb1_avg_recall,3)}')\n",
        "print()\n",
        "\n",
        "joblib.dump(nb1_scores, 'nb1_scores.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZWj-5H4y5on",
        "outputId": "8814a89f-3f8e-4854-a2b8-46396024b0b9"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***Model 0 Score:***\n",
            "Precision: 1.0\n",
            "Recall 1.0\n",
            "\n",
            "***Model 1 Score:***\n",
            "Precision: 1.0\n",
            "Recall 1.0\n",
            "\n",
            "***Model 2 Score:***\n",
            "Precision: 0.726\n",
            "Recall 0.774\n",
            "\n",
            "***Model 3 Score:***\n",
            "Precision: 0.634\n",
            "Recall 0.786\n",
            "\n",
            "***AVERAGE***\n",
            "Precision: 0.84\n",
            "Recall: 0.89\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nb1_scores.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Bayes II"
      ],
      "metadata": {
        "id": "R12H2xYWDJFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "nb2_scores = []\n",
        "\n",
        "for i, preds in enumerate(nb2_preds):\n",
        "  target = split_data[i]['test_labels']\n",
        "  (precision,recall,_,_) = precision_recall_fscore_support(\n",
        "      target, \n",
        "      preds, \n",
        "      average='macro', \n",
        "      zero_division=0)\n",
        "  precision = round(precision,3)\n",
        "  recall = round(recall,3)\n",
        "  nb2_scores.append((precision, recall))\n",
        "  print(f'***Model {i} Score:***')\n",
        "  print(f'Precision: {precision}')\n",
        "  print(f'Recall {recall}')\n",
        "  print()\n",
        "\n",
        "nb2_avg_precision = sum([p for (p,_) in nb2_scores]) / len(nb2_scores)\n",
        "nb2_avg_recall = sum([r for (_,r) in nb2_scores]) / len(nb2_scores)\n",
        "print('***AVERAGE***')\n",
        "print(f'Precision: {round(nb2_avg_precision,3)}')\n",
        "print(f'Recall: {round(nb2_avg_recall,3)}')\n",
        "print()\n",
        "\n",
        "joblib.dump(nb2_scores, 'nb2_scores.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtb4v1Oq2Tnm",
        "outputId": "e9ed8997-3f7e-4371-a353-f7f627edd219"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***Model 0 Score:***\n",
            "Precision: 0.254\n",
            "Recall 0.333\n",
            "\n",
            "***Model 1 Score:***\n",
            "Precision: 0.216\n",
            "Recall 0.333\n",
            "\n",
            "***Model 2 Score:***\n",
            "Precision: 0.217\n",
            "Recall 0.2\n",
            "\n",
            "***Model 3 Score:***\n",
            "Precision: 0.15\n",
            "Recall 0.238\n",
            "\n",
            "***AVERAGE***\n",
            "Precision: 0.209\n",
            "Recall: 0.276\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nb2_scores.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Bayes III"
      ],
      "metadata": {
        "id": "2UMQjM04DJLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "nb3_scores = []\n",
        "\n",
        "for i, preds in enumerate(nb3_preds):\n",
        "  target = split_data[i]['test_labels']\n",
        "  (precision,recall,_,_) = precision_recall_fscore_support(\n",
        "      target, \n",
        "      preds, \n",
        "      average='macro', \n",
        "      zero_division=0)\n",
        "  precision = round(precision,3)\n",
        "  recall = round(recall,3)\n",
        "  nb3_scores.append((precision, recall))\n",
        "  print(f'***Model {i} Score:***')\n",
        "  print(f'Precision: {precision}')\n",
        "  print(f'Recall {recall}')\n",
        "  print()\n",
        "\n",
        "nb3_avg_precision = sum([p for (p,_) in nb3_scores]) / len(nb3_scores)\n",
        "nb3_avg_recall = sum([r for (_,r) in nb3_scores]) / len(nb3_scores)\n",
        "print('***AVERAGE***')\n",
        "print(f'Precision: {round(nb3_avg_precision,3)}')\n",
        "print(f'Recall: {round(nb3_avg_recall,3)}')\n",
        "print()\n",
        "\n",
        "joblib.dump(nb3_scores, 'nb3_scores.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cn3QqWjQ4WJl",
        "outputId": "d62b66d3-1745-4f3f-e0ce-14cb844e0f4e"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***Model 0 Score:***\n",
            "Precision: 0.972\n",
            "Recall 0.985\n",
            "\n",
            "***Model 1 Score:***\n",
            "Precision: 1.0\n",
            "Recall 1.0\n",
            "\n",
            "***Model 2 Score:***\n",
            "Precision: 0.869\n",
            "Recall 0.905\n",
            "\n",
            "***Model 3 Score:***\n",
            "Precision: 0.837\n",
            "Recall 0.857\n",
            "\n",
            "***AVERAGE***\n",
            "Precision: 0.92\n",
            "Recall: 0.937\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nb3_scores.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression I"
      ],
      "metadata": {
        "id": "lnoeZm0zAbc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "lr1_scores = []\n",
        "\n",
        "for i, preds in enumerate(lr1_preds):\n",
        "  target = split_data[i]['test_labels']\n",
        "  (precision,recall,_,_) = precision_recall_fscore_support(\n",
        "      target, \n",
        "      preds, \n",
        "      average='macro', \n",
        "      zero_division=0)\n",
        "  precision = round(precision,3)\n",
        "  recall = round(recall,3)\n",
        "  lr1_scores.append((precision, recall))\n",
        "  print(f'***Model {i} Score:***')\n",
        "  print(f'Precision: {precision}')\n",
        "  print(f'Recall {recall}')\n",
        "  print()\n",
        "\n",
        "lr1_avg_precision = sum([p for (p,_) in lr1_scores]) / len(lr1_scores)\n",
        "lr1_avg_recall = sum([r for (_,r) in lr1_scores]) / len(lr1_scores)\n",
        "print('***AVERAGE***')\n",
        "print(f'Precision: {round(lr1_avg_precision,3)}')\n",
        "print(f'Recall: {round(lr1_avg_recall,3)}')\n",
        "print()\n",
        "\n",
        "joblib.dump(lr1_scores, 'lr1_scores.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLs186ZZKHhn",
        "outputId": "be2f35e8-e496-4fc6-9b7c-0be143631ee3"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***Model 0 Score:***\n",
            "Precision: 1.0\n",
            "Recall 1.0\n",
            "\n",
            "***Model 1 Score:***\n",
            "Precision: 1.0\n",
            "Recall 1.0\n",
            "\n",
            "***Model 2 Score:***\n",
            "Precision: 0.762\n",
            "Recall 0.857\n",
            "\n",
            "***Model 3 Score:***\n",
            "Precision: 0.681\n",
            "Recall 0.786\n",
            "\n",
            "***AVERAGE***\n",
            "Precision: 0.861\n",
            "Recall: 0.911\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['lr1_scores.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression II"
      ],
      "metadata": {
        "id": "OdxB8cUSDLqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "lr2_scores = []\n",
        "\n",
        "for i, preds in enumerate(lr2_preds):\n",
        "  target = split_data[i]['test_labels']\n",
        "  (precision,recall,_,_) = precision_recall_fscore_support(\n",
        "      target, \n",
        "      preds, \n",
        "      average='macro', \n",
        "      zero_division=0)\n",
        "  precision = round(precision,3)\n",
        "  recall = round(recall,3)\n",
        "  lr2_scores.append((precision, recall))\n",
        "  print(f'***Model {i} Score:***')\n",
        "  print(f'Precision: {precision}')\n",
        "  print(f'Recall {recall}')\n",
        "  print()\n",
        "\n",
        "lr2_avg_precision = sum([p for (p,_) in lr2_scores]) / len(lr2_scores)\n",
        "lr2_avg_recall = sum([r for (_,r) in lr2_scores]) / len(lr2_scores)\n",
        "print('***AVERAGE***')\n",
        "print(f'Precision: {round(lr2_avg_precision,3)}')\n",
        "print(f'Recall: {round(lr2_avg_recall,3)}')\n",
        "print()\n",
        "\n",
        "joblib.dump(lr2_scores, 'lr2_scores.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_LIYgjJKU7P",
        "outputId": "27fa1e86-b220-4009-8a34-204c03faee26"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***Model 0 Score:***\n",
            "Precision: 1.0\n",
            "Recall 1.0\n",
            "\n",
            "***Model 1 Score:***\n",
            "Precision: 1.0\n",
            "Recall 1.0\n",
            "\n",
            "***Model 2 Score:***\n",
            "Precision: 0.762\n",
            "Recall 0.857\n",
            "\n",
            "***Model 3 Score:***\n",
            "Precision: 0.681\n",
            "Recall 0.786\n",
            "\n",
            "***AVERAGE***\n",
            "Precision: 0.861\n",
            "Recall: 0.911\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['lr2_scores.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression III"
      ],
      "metadata": {
        "id": "nLRrQmZ-DLte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "lr3_scores = []\n",
        "\n",
        "for i, preds in enumerate(lr3_preds):\n",
        "  target = split_data[i]['test_labels']\n",
        "  (precision,recall,_,_) = precision_recall_fscore_support(\n",
        "      target, \n",
        "      preds, \n",
        "      average='macro', \n",
        "      zero_division=0)\n",
        "  precision = round(precision,3)\n",
        "  recall = round(recall,3)\n",
        "  lr3_scores.append((precision, recall))\n",
        "  print(f'***Model {i} Score:***')\n",
        "  print(f'Precision: {precision}')\n",
        "  print(f'Recall {recall}')\n",
        "  print()\n",
        "\n",
        "lr3_avg_precision = sum([p for (p,_) in lr3_scores]) / len(lr3_scores)\n",
        "lr3_avg_recall = sum([r for (_,r) in lr3_scores]) / len(lr3_scores)\n",
        "print('***AVERAGE***')\n",
        "print(f'Precision: {round(lr3_avg_precision,3)}')\n",
        "print(f'Recall: {round(lr3_avg_recall,3)}')\n",
        "print()\n",
        "\n",
        "joblib.dump(lr3_scores, 'lr3_scores.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0LR6kmgKawu",
        "outputId": "afdb1016-d1a3-4aa4-9674-646ef33b7617"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***Model 0 Score:***\n",
            "Precision: 0.071\n",
            "Recall 0.167\n",
            "\n",
            "***Model 1 Score:***\n",
            "Precision: 0.442\n",
            "Recall 0.458\n",
            "\n",
            "***Model 2 Score:***\n",
            "Precision: 0.367\n",
            "Recall 0.295\n",
            "\n",
            "***Model 3 Score:***\n",
            "Precision: 0.029\n",
            "Recall 0.143\n",
            "\n",
            "***AVERAGE***\n",
            "Precision: 0.227\n",
            "Recall: 0.266\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['lr3_scores.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-Layer Perceptron I"
      ],
      "metadata": {
        "id": "6bRIiRCDActK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "mlp1_scores = []\n",
        "\n",
        "for i, preds in enumerate(mlp1_preds):\n",
        "  target = split_data[i]['test_labels']\n",
        "  (precision,recall,_,_) = precision_recall_fscore_support(\n",
        "      target, \n",
        "      preds, \n",
        "      average='macro', \n",
        "      zero_division=0)\n",
        "  precision = round(precision,3)\n",
        "  recall = round(recall,3)\n",
        "  mlp1_scores.append((precision, recall))\n",
        "  print(f'***Model {i} Score:***')\n",
        "  print(f'Precision: {precision}')\n",
        "  print(f'Recall {recall}')\n",
        "  print()\n",
        "\n",
        "mlp1_avg_precision = sum([p for (p,_) in mlp1_scores]) / len(mlp1_scores)\n",
        "mlp1_avg_recall = sum([r for (_,r) in mlp1_scores]) / len(mlp1_scores)\n",
        "print('***AVERAGE***')\n",
        "print(f'Precision: {round(mlp1_avg_precision,3)}')\n",
        "print(f'Recall: {round(mlp1_avg_recall,3)}')\n",
        "print()\n",
        "\n",
        "joblib.dump(mlp1_scores, 'mlp1_scores.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMEFg5inDrhN",
        "outputId": "445c3ec7-ed93-46d1-f83a-6ce5fe14bda1"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***Model 0 Score:***\n",
            "Precision: 1.0\n",
            "Recall 1.0\n",
            "\n",
            "***Model 1 Score:***\n",
            "Precision: 1.0\n",
            "Recall 1.0\n",
            "\n",
            "***Model 2 Score:***\n",
            "Precision: 0.929\n",
            "Recall 0.929\n",
            "\n",
            "***Model 3 Score:***\n",
            "Precision: 0.845\n",
            "Recall 0.821\n",
            "\n",
            "***AVERAGE***\n",
            "Precision: 0.944\n",
            "Recall: 0.938\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mlp1_scores.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-Layer Perceptron II"
      ],
      "metadata": {
        "id": "V3dUu650DOE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "mlp2_scores = []\n",
        "\n",
        "for i, preds in enumerate(mlp2_preds):\n",
        "  target = split_data[i]['test_labels']\n",
        "  (precision,recall,_,_) = precision_recall_fscore_support(\n",
        "      target, \n",
        "      preds, \n",
        "      average='macro', \n",
        "      zero_division=0)\n",
        "  precision = round(precision,3)\n",
        "  recall = round(recall,3)\n",
        "  mlp2_scores.append((precision, recall))\n",
        "  print(f'***Model {i} Score:***')\n",
        "  print(f'Precision: {precision}')\n",
        "  print(f'Recall {recall}')\n",
        "  print()\n",
        "\n",
        "mlp2_avg_precision = sum([p for (p,_) in mlp2_scores]) / len(mlp2_scores)\n",
        "mlp2_avg_recall = sum([r for (_,r) in mlp2_scores]) / len(mlp2_scores)\n",
        "print('***AVERAGE***')\n",
        "print(f'Precision: {round(mlp2_avg_precision,3)}')\n",
        "print(f'Recall: {round(mlp2_avg_recall,3)}')\n",
        "print()\n",
        "\n",
        "joblib.dump(mlp2_scores, 'mlp2_scores.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIlQfxBuDy6q",
        "outputId": "81454608-9c94-4759-d1d3-4b73c29546d0"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***Model 0 Score:***\n",
            "Precision: 1.0\n",
            "Recall 1.0\n",
            "\n",
            "***Model 1 Score:***\n",
            "Precision: 1.0\n",
            "Recall 1.0\n",
            "\n",
            "***Model 2 Score:***\n",
            "Precision: 0.69\n",
            "Recall 0.757\n",
            "\n",
            "***Model 3 Score:***\n",
            "Precision: 0.81\n",
            "Recall 0.821\n",
            "\n",
            "***AVERAGE***\n",
            "Precision: 0.875\n",
            "Recall: 0.895\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mlp2_scores.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-Layer Perceptron III"
      ],
      "metadata": {
        "id": "UzUHM76JDOLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "mlp3_scores = []\n",
        "\n",
        "for i, preds in enumerate(mlp3_preds):\n",
        "  target = split_data[i]['test_labels']\n",
        "  (precision,recall,_,_) = precision_recall_fscore_support(\n",
        "      target, \n",
        "      preds, \n",
        "      average='macro', \n",
        "      zero_division=0)\n",
        "  precision = round(precision,3)\n",
        "  recall = round(recall,3)\n",
        "  mlp3_scores.append((precision, recall))\n",
        "  print(f'***Model {i} Score:***')\n",
        "  print(f'Precision: {precision}')\n",
        "  print(f'Recall {recall}')\n",
        "  print()\n",
        "\n",
        "mlp3_avg_precision = sum([p for (p,_) in mlp3_scores]) / len(mlp3_scores)\n",
        "mlp3_avg_recall = sum([r for (_,r) in mlp3_scores]) / len(mlp3_scores)\n",
        "print('***AVERAGE***')\n",
        "print(f'Precision: {round(mlp3_avg_precision,3)}')\n",
        "print(f'Recall: {round(mlp3_avg_recall,3)}')\n",
        "print()\n",
        "\n",
        "joblib.dump(mlp3_scores, 'mlp3_scores.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwYZC6K0D3Wn",
        "outputId": "b41b3c3b-090f-4ac5-dc32-620cec211791"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***Model 0 Score:***\n",
            "Precision: 1.0\n",
            "Recall 1.0\n",
            "\n",
            "***Model 1 Score:***\n",
            "Precision: 0.8\n",
            "Recall 0.833\n",
            "\n",
            "***Model 2 Score:***\n",
            "Precision: 0.745\n",
            "Recall 0.817\n",
            "\n",
            "***Model 3 Score:***\n",
            "Precision: 0.86\n",
            "Recall 0.857\n",
            "\n",
            "***AVERAGE***\n",
            "Precision: 0.851\n",
            "Recall: 0.877\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mlp3_scores.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Modify parameters and retrain\n",
        "See steps 6, 7, 8."
      ],
      "metadata": {
        "id": "iE2e4xgb-KI0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Analyze obtained results"
      ],
      "metadata": {
        "id": "E4_7R0Og_VV7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Here"
      ],
      "metadata": {
        "id": "G375gZAPCShB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References"
      ],
      "metadata": {
        "id": "ON4Bin9TE973"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Here"
      ],
      "metadata": {
        "id": "jgRlVqQqFBPm"
      }
    }
  ]
}